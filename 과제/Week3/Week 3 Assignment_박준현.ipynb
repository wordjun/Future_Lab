{"nbformat":4,"nbformat_minor":0,"metadata":{"coursera":{"course_slug":"neural-networks-deep-learning","graded_item_id":"XaIWT","launcher_item_id":"zAgPl"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Week 3 Assignment_박준현.ipynb","provenance":[],"collapsed_sections":["pxdxxHV2vqzF"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"FywnHwZSvqyy","colab_type":"text"},"source":["# Week 3 Assignment: Cat Classification"]},{"cell_type":"markdown","metadata":{"id":"XxzkgTo0vqyz","colab_type":"text"},"source":["-------"]},{"cell_type":"markdown","metadata":{"id":"C0B313pyvqy0","colab_type":"text"},"source":["## <font color=\"red\"> <참고사항> \n","\n","### 3주차와 4주차의 과제 난이도가 입문자들에게는 매우 높습니다. 그럼에도 하는 이유가 뭘까요?\n","    \n","#### 1. Neural Network의 구조에 대해 어느 정도 알아야 tensorflow로 구현할 수 있습니다.\n","- 하지만 5주차 초반부까지 가야 Neural Network의 구조에 대해 다 배웁니다.\n","    \n","- 그래서 실질적으로 더 열심히 하셔야 하는 과제는 5주차 이후의 과제들입니다.\n"," \n","#### 2. 그 전까지는 여러분들이 python과 numpy에 대해 실습을 통해 공부할 필요가 있습니다.\n","- 3~4주차 과제를 하시면서 모르는 부분들이 많을 것입니다.\n","    \n","- 이 부분을 직접 찾아보거나 튜터에게 질문을 하며 과제를 구현하게 되면 향후 python 실력이 5주차 실습을 하기에 충분해집니다.\n","    \n","#### 3. 또한, 이 과제는 코세라 내용을 기반으로 하기 때문에 배운 내용을 간접적으로 한 번 더 복습할 수 있는 계기가 됩니다.\n","    \n","### <font color=\"coral\"> **결론 1:** python 공부와 강의 복습을 목적으로 이 과제를 최대한 해결하되 \n","### <font color=\"coral\"> 과제를 다 해결하지 못해도 tensorflow 구조가 이보다 쉽기 때문에 충분히 5주차 이후 실습이 가능합니다.\n","    \n","    \n","### <font color=\"coral\"> **결론 2:** 빈칸이 이외의 셀은 알지 못해도 됩니다. (필요한 부분은 수업시간에 안내합니다.)"]},{"cell_type":"markdown","metadata":{"id":"WW6NNRsNvqy0","colab_type":"text"},"source":["----------"]},{"cell_type":"markdown","metadata":{"id":"Jj98UbZPvqy1","colab_type":"text"},"source":["## assignment 관련 설명 (꼭 읽어보시고 시작하시기 바랍니다.)\n","\n","### <font color=\"red\"> 0. 폴더 통째로 받아서 'images' 폴더랑 'Week 3 Assignment.ipynb'를 같은 폴더에 넣고 시작하셔야 합니다.\n","\n","### 1. 기본\n","\n","1) 기본: 'shift + enter' 로 각 셀을 실행합니다.\n","\n","2) ###START CODE HERE ### 와 ### END CODE HERE ### 사이의 빈 칸에 답을 적으시면 됩니다.\n","\n","3) (= X lines of code) 라고 적혀 있으면, X개의 줄 만큼의 답을 적으시면 됩니다. (물론 x개의 줄이 아니어도 정답일 수 있습니다.)\n","\n","4) 빈칸 이외의 부분은 건드리지 말아주세요.\n","\n","5) 셀은 위에서부터 **순서대로** 실행해주세요.\n","\n","6) 여유가 되신다면 빈칸 이외의 부분도 관심을 가지고 공부하는 것도 추천드립니다.\n","\n","#### 7) 문제와 주석을 꼼꼼히 읽어보시면 분명 hint가 나옵니다.\n","\n","### 2. 자꾸 error 가 날 때\n","\n","1) 처음부터 끝까지 순서대로 다시 실행 (특히, import 했는지 확인해보기)\n","\n","2) 문제를 잘 읽었는지 확인해보기\n","\n","3) 대소문자를 구별해서 적었는지 확인해주세요.\n","\n","4) 튜터에게 error 부분 스샷 잘 찍어서 질문하기\n","\n","### 3. 셀이 실행 안 될 때\n","\n","1) 좌측 상단에서 kernel -> Restart kernel 실행"]},{"cell_type":"markdown","metadata":{"id":"T7Tnwm0zvqy1","colab_type":"text"},"source":["------------"]},{"cell_type":"markdown","metadata":{"id":"HWK1X7qCvqy1","colab_type":"text"},"source":["## 1. Import Packages ##\n","\n","<중요한 라이브러리>\n","- [numpy](www.numpy.org)는 2주차 수업 때 간단히 배웠으며 ndarray를 다루는 라이브러리입니다.\n","- [matplotlib](http://matplotlib.org)은 셀 안에 그래프 혹은 그림을 그려줘서 향후 여러분들이 많이 쓰게 될 라이브러리이며 9주차에 특강으로 학습하실 수 있습니다.\n","\n","<알지 못해도 되는 라이브러리>\n","- [h5py](http://www.h5py.org)는 H5 파일을 다루는 라이브러리이며 향후 딥러닝 NN구조와 parameter를 저장할 때 H5 파일 형태로 저장합니다.\n","- [PIL](http://www.pythonware.com/products/pil/) and [cv2(opecnv)](https://opencv.org/) 는 마지막에 보너스로 여러분의 이미지를 test할 때 쓰이는 이미지 다루는 라이브러리입니다.\n","\n","\n","이 라이브러리들을 사용하기 위해 아래 셀을 실행해주어야 합니다."]},{"cell_type":"code","metadata":{"id":"LhOodJa7wfH8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1595156886140,"user_tz":-540,"elapsed":3946,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"98eeb9d4-e690-416b-c8b4-356cdb1ee804"},"source":["!pip install opencv-python"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rfR0la5Kvqy2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595220735214,"user_tz":-540,"elapsed":1029,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import h5py\n","import cv2\n","import PIL.Image as pilimg\n","\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VgxaPOv8vqy5","colab_type":"text"},"source":["-----"]},{"cell_type":"markdown","metadata":{"id":"fRysRUPJvqy5","colab_type":"text"},"source":["## 2. Data (업로드, 확인, 전처리) ##"]},{"cell_type":"markdown","metadata":{"id":"7vxkeBKNvqy6","colab_type":"text"},"source":["### 2-1) data 업로드"]},{"cell_type":"code","metadata":{"id":"-vgcQO9XkeqJ","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DIUW1qnvvqy6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595220820281,"user_tz":-540,"elapsed":909,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}}},"source":["def load_dataset():\n","    train_dataset = h5py.File('/content/drive/My Drive/Colab Notebooks/Week3/images/train_catvnoncat.h5', \"r\")\n","    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n","    train_set_y= np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n","\n","    test_dataset = h5py.File('/content/drive/My Drive/Colab Notebooks/Week3/images/test_catvnoncat.h5', \"r\")\n","    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n","    test_set_y = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n","\n","    classes = np.array([b'non-cat', b'cat']) # the list of classes\n","    \n","    train_set_y= train_set_y.reshape((1, train_set_y.shape[0]))\n","    test_set_y = test_set_y.reshape((1, test_set_y.shape[0]))\n","    \n","    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ngzfPPffvqy8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595220825376,"user_tz":-540,"elapsed":3134,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}}},"source":["# Loading the data (cat/non-cat)\n","'''\n","훈련데이터의 꼴: (x, y) - 성능향상에 쓰이는 데이터 꼴\n","테스트 데이터: (x, y) - 성능 측정용\n","\n","orig-오리지널. 전처리 하기 전의 데이터를 뜻함\n","train_set_x_orig: 즉, 전처리가 필요한 데이터\n","'''\n","train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXzrvSMq0dL6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1595220827830,"user_tz":-540,"elapsed":831,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"38bb062c-2c72-459b-ad15-1d9e301beb1b"},"source":["train_set_x_orig.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(200, 64, 64, 3)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"KL9lsTbQvqy_","colab_type":"text"},"source":["**data에 대한 이해**: You are given a dataset (\"data.h5\"에 저장되어 있음) containing:\n","\n","- a training set of m_train images labeled as cat (y=1) or non-cat (y=0)\n","- a test set of m_test images labeled as cat or non-cat\n","- each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px).\n","\n","**<부연>**\n","\n","1) training set은 우리의 모델을 학습시키기 위해 사용하는 dataset\n","\n","2) test set은 학습된 모델이 학습하지 않은 data(test data)에서도 일관되게 성능이 나오는지 확인하기 위한 data (일반성을 확보하기 위해 존재) (5주차에 배웁니다.)\n","\n","3) 이미지 1개 (x(i))의 shape = (num_px, num_px, 3)이다.\n","- (3은 RGB 채널 각각을 의미)\n","- (num_px,num_px) = 세로 픽셀 수(행의 개수), 가로 픽셀 수(열의 개수)\n","\n","4) train_set_x_orig에는 training data(shape=num_px, num_px, 3)가 m개 있다.\n"," **=> train_set_x_orig.shape = (m, num_px, num_px, 3)**\n","\n","5) 실제 data 업로드 방법은 이와 다르니 위의 업로드를 유심히 보지 않아도 됩니다.\n","\n","6) \"_orig\"는 문제를 만든 사람이 아직 data가 전처리(preprocess)가 안 되었다는 것을 알려주기 위해 변수 이름에 덧붙였다.\n","\n","(물론 ndarray가 어떻게 생겼을지는 아무도 모릅니다. 그래서 항상 shape을 찍어보는 습관을 들이기 바랍니다.)\n","\n","(이를 통해 향후 2주의 과제로 ndarray에 익숙해지는 시간을 가지기 바랍니다.)"]},{"cell_type":"markdown","metadata":{"id":"kNzSn0G6vqy_","colab_type":"text"},"source":["### 2-2) data 확인\n","\n","#### matplotlib.pyplot가 주로 사용되는 2가지\n","- data 업로드가 잘 되었는지 확인\n","- 학습이 잘 되었는지 그래프 그릴 때"]},{"cell_type":"code","metadata":{"id":"9lLZ_Aybvqy_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"ok","timestamp":1595221402175,"user_tz":-540,"elapsed":1022,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"77c2dd09-ee91-46e9-b691-fcd8cc11bc3a"},"source":["# Example of a picture\n","#(X: image, y: 0(non-cat) / 1(cat))\n","index = np.random.randint(0, 200, dtype=int)\n","plt.imshow(train_set_x_orig[index])\n","print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["y = [0], it's a 'non-cat' picture.\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO19abhcVZX2u2seb1XdeUxuRkIIEDBMKjQGsdFWEbX9RNuP7lbjiNrOqO2As7YDftIqLQ6tKAhIQ6stIoKAMs8BMucmN7nzULfmeX8/qnLWWttciEIqtLXf58mTfe/edc4++5xza639rvUupbWGhYXFXz9cR3oCFhYWzYF92S0sWgT2ZbewaBHYl93CokVgX3YLixaBfdktLFoET+tlV0qdo5TaqpTaoZT68DM1KQsLi2ce6i/l2ZVSbgDbAJwNYB+AewGcr7V+/JmbnoWFxTMFz9P47MkAdmitdwGAUupKAOcCWPRlV0rpA8aExyNPXalU2ED5ObfH7bSrlTL93ucV46o1OobLJY0Wn89HfYpOkMvmxDivl+ZV5XOqz99p65pmv1/cQNLGxbhc9HO1JI/v89F1Fks1p+3x+cW4Wpk+50FV9PV2xJx2qVSkDo9PjEvnCk67UqtBguYBTdemDEOwXCk5bZdbXme1xualNBvnFuPEfa/JLx7lofvL175WldfMuqCN9fDyZ4fNSdfkfDXo3MFgSPTls1n6wSU/x5+XcrHMxolhYv4eYw1cLvpZseelVCqLcX72HOTz8rmll0ZDa228QY3zHuyXh4gBAKPs530ATnnyj7igUF/IRKJD9EzPzjht5ZdzjXa0Oe3k9JjTjg93i3HJ9KzTDoYDom94eKnTDrAbdN/d94txPb1xOt7snOjzuelzpQLdCJ9LPhxV9oJUjRsbCdBLN7d3UvQNDdCLumMPPWDx3mExrjBNa9WOjOi76FVnOe29I9uddq1dHuO2hx9z2lOZvOjzeGi9UYg4TbcrKMZNzOxz2oE2+cckmaF7oXz0IkVibWLc5DRbg5L8oxNop/vr9dLxUwtJMc7PnpdSZUH0dbH7mUpRX6kk70u1SnNcc9w60ffgnXc7bVdUvjJdfZ1Oe2znuNP2hMUweNmzE4+1i762UNRpu110nfv27hfjli5Z4bQfffAReYIDXzha/oHgeDov+yFBKbUJwKbGT4f7dBYWFovg6bzs+wEMsZ8HG78T0FpfBuAyAPB6vDoeq//JK5VSYlxblP3lzqdFXyHP/khw878qzb5EG/2VndmzT/QNnPw3Tvueu+5y2kF3RIyb3EfzqhbkN40rROdWVfr29kakmb3xb+hcH7v406LvOeuPcdpd8g88RkbIkli6hsaNjk6LcUFN5ujA4IDo27Fjh9OuVchU1yX57R2J0HUHO6SFtHPXbqft1rQexbK0Tf0hWp+FlLSCli4fdtrJNH2jTs6Mi3HBEFlgeVUUfW4PXWeNuwVl+e1VcfN5me4buQLhMFkmPr/8Zi+zwxvGGAZWL2Hzlffa56NnYiZKVgo/FwBEw2TRVAz3LZMh6yyfKx709wCQzbL3Qsln391Yg6o8tMDT2Y2/F8AqpdQypZQPwGsB3PA0jmdhYXEY8Rd/s2utK0qpdwK4EfUdne9prR97io9ZWFgcITwtn11r/SsAv3qG5mJhYXEYcdg36Di0rqBSqPs1FcmQoEAsDo5as0T0bd+912kffQz5slu37RLjYnFygoeWrhV9X/vMt5z2c9af5LR7O1eLcftnydf3VeWG4j++4c1O+5JvkS+eKUjfqlAlWuSq6/5L9IXDtE178Sc+JPq+94MfO+27HqVrC4SM3dsI83PzWdEXCNDYVSvo2m57Yq8YNzk1QZ9JdIo+5SHf0OWh44ekGwp/iViIhEvOcYb55qkMHc/tkk5lpcL2bspyj6TM9nVcYNvbRmiI103r4fZKzzQWJV85GCJnvKIle5DJ0p7G/sk9oo9TexmDqlU5RqmxtymRiIlx3GcfHxsTfaUc7UEszNM8jK0DVEp0brdLrpXCgXVdPG7GhstaWLQI7MtuYdEiaKoZr6Dgd9WpkFK+JPp6WeDMwoyk5SI+oomeeID2AP0hSZsVkmRyvv+d/yL6xnZRgMmWh+9x2stZsA0APHr/A0776OOOFX2TjJKq5IhOSqXnxbh4D5m0l1zyNdH361/TFsfKnrjo+8mVP3PaoQiZyMWSpKR8ETIR/dIaRU9fj9Pev59inmo1aT6vXLnSae8anxJ9HV107o4eWlPzXPNTZMKO7pkVfZ/6xFec9kc++gmnHe2Q1NX4FKNITQtUswg9RffaZUQD+v3kX7jcBvXmp0fcpYmGC4Slmd3Gnr89e3eLvgAL6EkvyGfTzaInI1Hm1sRl8FC5SNdSzEnXSzMal0evx+JRMc7np/l7fdLILxSehHNrwH6zW1i0COzLbmHRIrAvu4VFi+AvTnH9S+Bz+XSnrxcA0NEhE2F2jBHVtGLpKtG3dc8Wpx0OEs0SapNcUIQlKdz2+xtFn1IUOupS5DMlYtL/87ho3OObZZJMIkbn7uihpIRspVeMe3QrhU32LRkWfcP9NPZVLz5d9NUY2ZJxk99frsqtlV0PPei0j+1PiL4XH0fhszu3UQKi6lohxm2fon2GrJEk9crXPtdpdw+OOG2PW9I9pQwd8/hjXiX6jlpJIcMLaVrTPeNPiHHf+0+iRH/0kx+KPp+ffNZamXz2TFruYXA6E25Jja0+ivZFam7ym0vG91xHD92XyUmZoORhGX2zUzJ0WVdpTdws9yMclPtJJcYtj43OiD4vc78LzJ3v6ZL3tqO9y2nvGRkRfelU/fgaWDTrzX6zW1i0COzLbmHRImgq9VbVGuli3aTr98uE3/52iprbtUdSH1Ev0Rhc4OFzF39KjDvnxWQ6xqPy75hi5vm9d//BabvcMsNu1w6i3gI+aS7GYkQbTdxK5tvKda8X43r7T3DaFYPyuvxHlzvtsUkZSdXV1ee003mi9naPTIhxPYzWcRlhVkWW3dbO0ur25WWUXzBMNNGZZ54l+uaSFG2XyRM1tn2b1CUpZyjSbGqvdMvCLz+ajpElE/auux8Q4woZCqX0GvnyiglMVIq0jtVCQYwrstA1j1+GZrpZCpufZazlc/IYPPIu0S4prywTr/AbYYSaZbDVWARgLiPdiSLLZoOhFcI9aa7LkU7LZ5Ob8VwMAwAO6HxUDlPWm4WFxf8i2JfdwqJF0FQzPhDwYe2yut5F34Dcadz8W5L+aY/JxAzNxBqGV5Bexmc++3Ex7hvfJDOtv09GMH3u8yR++3wmLnHZpZ8T45SLzK/RPTLRJhhkGnSKTKrsww+Lca9eR2axx9AzO/vss532eWefJvp4Ys/bPvhZp718+TIxzsO2bLvbjewUkB2XYQkooWi/GPWu933MaXctkcd/+7v/0Wm/9MUnO+0P//ulYpw3QElJ+VkZGfelL13mtNefsMFpv/Lc14hxExPkolTy0idRTD+uVnmyBA8mclGWkZlFJh9WUTRuiRE56WbhgVyvEADSKZ4MZOyy18gdKLNz1wxxiVyO7oXPK1877q54XDTfTMqwydm4ckm6K7rhGjwZuWa/2S0sWgT2ZbewaBHYl93CokXQVJ/dH/Bg+Oi6r7t27VGir6zIp9m1WwotbN9BVJxvgjJ/9o9JfcvTTiPf8MJ3vlf0tcfJR/vef1zttKemJQ/y8pf+ndN+9NG7Rd8rzz3Hac+lyDnqWf5CMS5TZnLRc1KI8eabf0vt638i+hZSRI8FAhStl8nKTCt/ifxEt1dSmDx2qrubhCRXn7ZRjFuzZo3T3mKIc37nWz9y2r0ddPxqUfqQd9xEwp2nnHSG6DvjDKIf33HhO532W962SYz7wuc/77SjbXKfhYtSeIM8M0w6pkxe/k/EJaanKVKwxKIoe5atFONSKeZTu6XPns3S54IeKVGeWqC+2UmKjKtJ1hYepjcfj8psR6GXzz6YLkuRULBaCOWyIQJiSv8fBPab3cKiRWBfdguLFkFTE2HiiYg+/cwD1Tbk35nHNm+jcXGpY+71EN1xz12UBNLTNSjG3XnnnU67nJcRUmWm37V2DVFNtZocNztFUWHdQzLB5VfXXem0jz7uOPpMTl5LHzMRswVpz6WSJBTxkXf9s+jLsqiuqRJRar19UpNPs4ooKxPSrFwTJepm7VHkKm38+zeJcVsnyLyt+iR9195JyTQjT5CJ7zLUJdYeS/NyeeR1Kg/N45qfk8L4C1/4MjFu+3ai3s4//42iL9pG9GyeuS7zSZmMEmEJSul5KaLhj9G1lZkYRucSGfG39niK+NtvVGJpi9A89o+Mir58iua1ME73paOrS4ybn6W+cFCud3cnjeVJOKZufN8APY8VozTU9EzjurVNhLGwaHnYl93CokVgX3YLixZBU3125VZaNdyV/n6ZWcQ1FY85+kTRd9vvyRcf6F/utH95gxSo2LV9xGkXDZ/9uc891WnPzZLffNx6ScHc8ms65voTjhF9Z5xORWpdTPyvYLhIVZaFVTa8p444+Wu5SRmO29VFYpELimioYkneo05Wuve01UOiT41tdtrBAI1TnVK84qQXvtxp3/2oLOSz7hhaq89+jAQzv/XvXxXjTnke+ZCesPQvNYiGuv+hR+nYR0sKcH6eQmLdWoZJH38irff0NKsR55Ghom1xogfnk1L80+Ol/Z4K0/OPDEqaL9xGfn/QK/dBXJru58SoFLaossqzlSzRYTGDXpubYlWKjXLivYwiLbNibZWqfIYjMbqWmlFm+0BI+czEDEpF86lrXMfBfsmhlPqeUmpKKbWZ/a5dKXWTUmp74//Ekx3DwsLiyONQzPgfADjH+N2HAdystV4F4ObGzxYWFs9iPGUEndb6NqXUsPHrcwGc2Wj/EMCtAD6Ep4DL7SJTxCV1u2sgKuHW394u+tq7yVQNR+lzG18oRRe+853vOO1MUUadXfBmEpiYHKcIvfHxETHu29+5xGl//uvXiD5PlEyn8UmiZ2ouGcWWLTIz0yujseanyV856WhZbtnFxlYUHbNYkiZyhZlwU7NSzyySp+O3x8ng2mZEyfXspTW4+657Rd/ZZ5/rtDt7aL2r7qQYt3eSjlFyScGRrTso+rC3hyi6MqTblMmTOzRv6Ltlc2SSxxO0HrPzUuc+w0prewIy+66bPTtju6mcta7I77nJnSQksmTFctE3O0N0Xm5qQfTBRefzeyjDMZeSVKTfTyZ4sSij/JIpela9LCPOH5HuhJu5h4l26YYcc0y93NmN10vXVkx10Z4nR4/W+oATNQGg58kGW1hYHHk87dh4rbVWSi26y6eU2gRgEwAo90H3DSwsLJqAv/Rln1RK9Wmtx5VSfQCmFhuotb4MwGUAEIwE9eCSulkVazP39OgPgf9YWXZpdoZMp95e0mmbmJTRTPc8cIfTvuJH3xd9S5ZQtJ320C5nxIhA+9TnqVQRlIxS2r2Hor3aWNRWOCBNqjaWPKLdcokX5sj8DwSksMV8ipWUqtEutRkQlUySOZ1YLaMIl/fQvPbsJtN6YkImVdzHylxNTsrbt2UbyT2PTux02t6gIQwBSvJ56JHfi75cgdaKR7iN7t8hxvncZNbfert035Yvp+SlR59gAiHGU9vZTdFw4yPjom92nu3O+8nk9niMg7CvK7dRP7XA9eq0UV6K7dxzQQkzmSbABDFckPdTa9qBzzETX/uN7BaW7RKoSXclEKkf3/UkX6h/qRl/A4ALGu0LAFz/Fx7HwsKiSTgU6u2nAO4EcJRSap9S6o0AvgDgbKXUdgAvbPxsYWHxLMah7Mafv0jXWYv83sLC4lmIpopXaF1FtVb38zq6ZNbR/fdRNlt6Qepl85K8WpGfeMKJUjQwGCK/NFeUfuj0HPlTlQr5nlVIimSClUXq65NZb8MriCrLZsiPU4Z/5vORH5fMyPK8HlZu2OuVflciTmuSTjE6ySVvU8hF0YcLRgnh8QqtTzxOUVwrIzLSbucErU9np8wy7GNln/94z2+cti8gz/XoVoqM6+6WewepDM15fpbWe2mPjJz89KdIvOLB+2W2mddLtF8oQs9ARcu9FMXKUsUH5HOlFM2jbyllO2ZykuaLd5PGvrnd7GFlmcuGr9+RoM9N7Kd9inBE7uPMzdN9CUflPpGH7SVk2P5AuSb3WTR7bvdPyXvxwOa6r57Ly+eNw8bGW1i0COzLbmHRImiqGe92uxAN1yOJfvWL20TfmaeTZtnOnTIai+ux1Spk5mzZslmMc7vJ/urqaBd9uQJLgmAm1sqVq8W4rdu3O+3kgjTxM8wkd7PIKa9HmpUuF6NS8vIYHmYjTs1IfTpOBy0k6Zguj6ToakzIYe3a54m+1OOkCzcxTqb649Mygi6+hIQtZuZlhN7HP/VJp+3zkul49bWXiXG93RRplskZNOIsmdbJOTJH/f4+Me6oVeud9j13yjlmMuRSLV9O55qck/RaKk2U5XNOOUX0Tc+QSxiNkguhJ6UZ7GNrrEtGkkmNRUTWZBJOrUL3SWv6XDYnXVHNte2NY3C6rFKl9dYG89aeIBdFeWVfvlo/X03LY4vzLNpjYWHxVwX7sltYtAjsy25h0SJoqniFP+jTg8vrdJZZjrani+ifmRmZycXn2MWE/CpGfVp+zI64pGC4rnaC0SWTU8a5mL53NCoz88plRt+x8rzmtbTF6XN/IiNQJf94aaek3sDOnQb5l16/pKvy00TxvJAJJQJAZc8jTrurnUKSH5+S+wruBNGIe6al4EOalXc+7bR1Tnv7jkfFuOlpynq7+NOfEH2REIUMb3gO7SuM7pH7FJUS7VPs3ClLWH/uy1+kz02MOO1AVDqsgQiFtyY6pGjE6ATtA3R00DNRycv1yKZpT8cLefy9u4kSLBjZbJEQ3ZtYhD1XE7LMto/RawZTC1+Y1mB2gdbHI5MpsZYJrUQTsvPAPsAjv92BzFzeCk5aWLQy7MtuYdEiaCr1pqCgavVTdhja8ONjFNG0bt060Tc9SVTLqlVEGe3Yuk2M45FgQUMLfYIJI1SrPMpMUnSc/to/IfXGRlkZqnUnkk5etE2aVOUymXo1kyIpMJrLL+dYqZKb4GE0Yi4jTd9YjM6Xr0lzNNpB0W/j80RJzWWknpnbQ32BkJxkSZNZfMcdlElYM84V8JFZ/M2vy1JWUxPkHv3yFySocN7L3yDGPeckKgmdNCIns3mix4oVFk1mlGXu66DovVxFUmpLl9N6ZLNEnWq35LXm5oim7O2SkZPKx6IZpUcF+OmerTuFXKrcPfJauGZc2dCW87OswDYWfen2SRc7FGLlsIxsyvl0/bpr1cXrQNlvdguLFoF92S0sWgRNNeOhAJe3bppkC9LcWrKM7Q7vkxLLw0so4WXr9i1OOxSSZvDMHGmF5T0yIWD9c8g12LKFzP/uXrnjvnkzReW5Dcnftg46X6FEO9imrK/LR5/zBeQxNLOYqyG5aVpi2nXZPJmV0bC0HbMLTMxjWEaMvetNn3bar/s/r3XakV5pmrrYbvmOERmx2D9I92J6kkzmP9wqxSVe8hKqeFswpLtTaVr/x7eQGIaZ3LFtJ633XFqyAl295CaUWYRbz5BRWolp1Q0ukwk5o2NUzivMnhfOrACAO0iuS8Et5xjpJfN5ela6Mu3L6PkpxclFO+VlJ4hxmx9ZPGkoFqH7W2OuXC4j51FiDEJqVroJ+Xx9bPVJyrnab3YLixaBfdktLFoE9mW3sGgRNNVnr1WryGbrvkY0Ln3lgQGWDSX1/pDOkn+/Zx/5YPGoFAgos2yiaFT6dcUKj3yiyLutO54Q4xIJ8p92Gr5sTzcdM8dooXBI+tRTkxQ91d4jqb2BYRKRMDXfh4bIVy6XyGdPxORaBeJEJ82npAa5L0b047W/usVpn/8Prxfjlg2S35ivyqiwbdu2Ou3f30LU24QRbXjxxZ9x2h/5yEdE3wteQEJGd99NGvKDS6RWfpVlg7V75f3kmh0p9gxEi3K9eVTlwoLUdZ+cpjnzqD53WT5kLg/tn2TzMgswX6b9iESfzO4Lt5M/v1AmIdBoQM7RH6fNmkBMRk5mWTlxxYJC9zJtf7NvalxeZ+3A1orcOhGw3+wWFi0C+7JbWLQImqtBBzK1i0YUVLZANIM2w/hdnMoiE8jlldN31+iD+yekwIEvTLSLx8/KLJWkCTvDtMLi7VLbvsLUBI4/jqiViX1Szyzno2P2JCTNMrmXjr/uuONE37ZtRAmuX0eiDtPj8viBIF3LhW/7gOjzeykRJDlH5wr4pCvw5S9+w2mPzci1uugiKt0XCZNpPZ2XEYWFEt2zH//kR6Lv0UeJajr1VKoKe+XPfirGdXDXqCCpJn4/e7v6nXZnXBYgKrCIxXJRmueDXSR6wc3isKH/5/WSmV02Eqy4VuDQgNTyi7HEm1SWzH9T65/rErpcco75DNFoHha9mJyX9HRbkEpIuQ1XNxyrvwvZopw7h/1mt7BoEdiX3cKiRWBfdguLFkHzw2U9dWcjX5AcwTSjoUyfKdZGfmMno1nCIUmDVFnYqtfQ9/Ywn+z+e6luGA/TBaSfPjcvwzfHmCBBNkN+YptPUkZLB6hE8eSYpKsSTJ+8kJbXGfKT/zc/Q/7r3Kz0ZV2slG9buFP0caGF/n7ycz/wgYsgQX/nQ0E5/29ceqnTTrL6cwlDEOTT/0mhue973/tE35lnbnTakyxrsb1dUpFf/epX6fiGSOhV11zltH/6M2r73PK+l5hCyIyRqcjp2CBLWVNKhpUqRgEmEnJ/wx8in93MkgwFic6rstvpqrmNcXTualVms/Fo64UU+e9uI7ON1xwY6JfhzwfekW0Le7AYDqX805BS6hal1ONKqceUUu9u/L5dKXWTUmp743+zUqOFhcWzCIdixlcAvE9rvRbAqQDeoZRaC+DDAG7WWq8CcHPjZwsLi2cpDqXW2ziA8UY7rZR6AsAAgHMBnNkY9kMAtwL40JMfTUE1aDTlkWYON2xMSo2LOjA2BjVDP8/LaLnUfFL0dfUSXdPZQ0bIitWrxLjj11G56O989z9E3+lnPN9pL2Gm+qc+JPXXbvwfEmv44te+Ivpu/R1FtX37Mnn8t77lnU5740aKQPMqWS6olCe7LxiUkVphFrnF2Z+1xxwjxqVz5BpwKhIAyky7XLHSR6GAFOn43BdIIy6TkVFns0wTn2eY3XjTzWLcblZW2m8IjkQjdJ8qJbrXs4bme57RuK6qpNSqjM5LtJPLUyrKY+RKlKW3pENGX8YZvWa6n2ypxPoUjHHRMB2jaGQI8pLfc+PkOpoaiMUcnSwWkX1QB96nZ6hks1JqGMAJAO4G0NP4QwAAEwB6FvmYhYXFswCHvEGnlIoAuBbAe7TWKaXoL4jWWitllsNzPrcJwCYAcHns5r+FxZHCIb19Sikv6i/6FVrrnzd+PamU6mv09wGYOthntdaXaa03aK03uNz2ZbewOFJ4ym92Vf8KvxzAE1rrr7KuGwBcAOALjf+vf8pjuZTjHx5Q1jiA2ST3VaQf6gqTLxRkoaL5ogx1LabJD1u9WtZwe/hhots4HZNMSt9+mqndmMKXDzz8kNNefzyFul53vRRbvP/eB5y21yPptT/cfqvTfutbN4m+fI78xttuId/2lJNkPbelK2i/oFSS/h/3Fb1e2hdpa5drGmJil/ma6YcyuortARSKkq6qVuj48ZikAFNsXbkCz7Zt28W4gQGiPqdmZFjwg/fROg4PUdhrV48UK73/YdLKjxga+51xoqi2bKVx3QNSX75Sovtklsjm4qWpBamApBSpx/B9qEJOKtr4vPRFl0vLZz/MRSZdRBF3dkmab36Gns1Im5z/Af6OW9wmDsWMfx6ANwB4VCl14Gn/COov+c+UUm8EsAfAaw7hWBYWFkcIh7IbfwcW3+I7a5HfW1hYPMvQdN34AxF0ZtZbmmUMuQxaLsCEAnlfKStNpXyRzNFdhvDENBMxWL2GTPyAIVr5wEMPOu01a9aIPn7MD32YIsbuu/23YtxvfnON0z5z48mib8NpRO25Ifc0uQgnN8dvvlXSVZv++Z9pXEmKV8Q7iMbJZOh4Y1OyHHI7yzbj4iAAEA4RrVPJVtk4ea72doqo8xkljfijxd0JHk0HAOPjFPEWMdy3hx+izDlelmt0v7yWAiuLnTPcwyVLKFMsEWemr6Gv7naT+ZxekDSij12c32OU7GK3MJuk6LdKRT6bVeYC/YmQpKL5V5hgZLlsuALM3P+Tqm0ORfoMUW8WFhb/e2FfdguLFkFTq7j6Qj7dtbJuPpZK0ozn2ut8xx2Q1Vr5OLeRwc938YvGTr2LCWDwMkCdnXIXmZtsqZQ0b48+msr7XPufJNbggkyYKRTJnHvDP71d9H31km877UhMJjP4mQZbuUDmc8SIXNu9nXa0O9vlrmwsSmZrhZVrGpuUVUXbe8iM9wVlYolmSRy+GpnjWt4yVFhCR74kTVMPi6kYH6fknLiRZOLz0fGnZmQSy+pVVLU0W6Tjr1y1XIxLJCjSrmDc92CATN9AiO5tviJ31fMlMt0DARmx2JagNR4YlGIkVSZowsUxzKjEkJ/WeN5IsJplLmaGJcJAStuLZzjgk+7EgbJlsyPzKOf/pHZw/fMH+6WFhcVfH+zLbmHRIrAvu4VFi6C5uvFao9igE1yGv8195WBY+qhcDJD74qZPPct8IdPvWsJ8rclJ8g1LhlBGlGm0jz4hNeU5WZPVzEc16K8U87uu/Mm1ou9V/3CB0/7yly8VfcN9FBlWdpGDvJCWVNBRLFMvtSAjALM5OncbE/3wGUIIXkVrqmqyL8uooVqN+bxGNqLfS65htSJ9yAKjwDritD9g5kfwcnptRlRYtUZ7AgvzFD32QUMo48dX/MBpz83L8tZu0LM0MDTstJNpSWspF82/YAhfTo6Rfz82Nib6+I4X30Py+GQZ7NhS2mcoF+XmB48m9fvZOhr0IN+7Uobg5AGt+1rNcPQZ7De7hUWLwL7sFhYtgqZSb4FIUC9dPwwA2LFjh+jr6KBoLJMOy+XITOaRZTGjLFI6TSYsN/0BaQLFWSSVx9CqGxkZcdq8rJB5zD/cRiIU5YKkUhIBpiVulgb2EDV2/fU3iZkAb9YAACAASURBVL7Tn0+6bVxfry0gTeT8AlE1qibdkAAzrQMBco32Gdpsff2UTOPySOptnkWCRbxkBvuMrEUupZYvyusU1CeLfvOYac7MHA2E5HXOzNKcY3GiY0N+Oe7U059Dc5+XyTR9/SSz8MhjFJE3tFRSaJyyq5hlj9l114zXJceiNotFcg2qVbkeXHvPFLaoVuigblaGqlqSrgan3vj7AhBdveO+EeRSeUu9WVi0MuzLbmHRIrAvu4VFi6Cp1JvP58XSoXqtrG2PbRF9XkZb1Aw6jAshcP99oK9v0XErjzpK9HHK5PGHNjvt5atl6KVmvtYaQwCD72+c/9p/cNrPPfkUMe4V577aabe394u+JKMLz33Zq0Sfn/mvPGkqb1BvKebLdrRJijEUYLeUxbcGa5Ie9NY4dSjXu5alPYhakNVRc8l9kJpiobQVY2+C+Zdelq3l8clHTrOvm1RKXicXoOSM0r99/UtiXLVKi5Volxr4qQUSUOpsp72JbEZSlgWRhSm/Azkd5jVqxIVBP7uZq180MhqrrKagx/CovWxNanwPxi0HegX1KdfbYx70ILDf7BYWLQL7sltYtAiaW/4JREm4vPLvDKfAOIUGSMqBa2yZtBk3s83oOk69nff35znt2dlZMe6MM85w2ieeeKLou+B1FP32qteQqf7TH8souYveS2WRMnlJ43Qk6Fp27JCZaAOMJlIVMmk7YvI6O1jJIbikeY4Co9jyZN66SnPGOGYueiOiq4v9WOb6dG7pMrhA1J7HEBzxuliJbHavjUA+cAeiIy7nUSjT/fzmpaS/P2foBkYi9LmaNso+u8nMrmi6FuWWLonOkVlcKku3hgsnBww3xBOkNaiFWcahlvedZ3KmDY19TsUVWLZjKCxdBh4VWjKiNjMNkREbQWdhYWFfdguLVkFzxSuCPt3dEK8wE/j72M66acb39pLIA08aMCPtRkdHnbbfiLLiSQoTrBqrKRfNJahNE59HhV1/5X877WxaJjb8n1e/3mlf8ZOfLXqM/n4ZAZjL0HUHvGTqpeeMaMNe+htdnZLSzOOjjzttXaG1Ss1L07G9k1yGUEhGY4VjdC/cbYzx8Mn5KjfTjNNScEQrXjGVm7fSfC4yizmflxFjfOc+UyDTvViSLlpnN5MaN3alP/nZDzrt2++41Wn7glJcIsXWPpeVEW4uJi3t9xuuDGMkeHVWI4dFJHrNs8q4gNSay+cp6SbeIdc7zBLEsgUpvtHTU7+fD960Dem5nI2gs7BoZdiX3cKiRWBfdguLFkFTqbdKpYKZmXrGFhcJBGRGmZmxxjOGuM/OhSMB6Q+bx+AlhU8+mbTcucADALzuda9z2j/+8Y9F31133eW0jz6WNOW9JenHbWOiF7+/7S7Rd+KJxzvtiX17RV9PJ1sDP8034pcZa3se/KPTLqZ2ir6FWfLvY4y6qRllgpNjNOdxqdEIX3TIabcNnuC0A7FlYlyE+faBgCzi6+LUFhOGUFV5X3i1Io9xz3jCYCRMz8v+MblubTHaL9CQtNmFF/6L0/7ljb9w2t1hWVqJC18qZYo5MorRoB8rLHKQR/JpIxsxz8otKy33JiJRdkzFBCqMWqk1JiAaDstMxfXr6/UItv5hFIvhKb/ZlVIBpdQ9SqmHlVKPKaU+1fj9MqXU3UqpHUqpq5RSf1ImwMLC4tmDQzHjiwA2aq2PB7AewDlKqVMBfBHA17TWKwHMA3jj4ZumhYXF08Wh1HrTAA7YlN7GPw1gI4ADNu8PAXwSwLee9GRuN9pjdWEHv1caAsUcmefKUAhIzcuIqQMoGOWI3Kz0TWYhZQ53sJNVEn3lK18p+k7fQBVTn7fhNNG3ZQcl72x7YpvT/vsXy4SWZUNUmfS2O34v+vxeus7BQam1l5ql41eyZI7Njt8jx82RGR8LShon2E60YjxKt7dUkKaj1kRFzs1Id6hUpWPuGaG+aI+k7wbdZHL6DM01l4tdm6K2Mr5ehBlvPI18aLFEz0R7u9Tb97jJjP/NjbKY8Le+83WnHQwQBcgTqgCgUiVfRhnfgTwfxaVkhJpLsToG7GPaTEzhAhVGgkswSG5DuULulumS5FlkX1tQup/Dy+piJL4/rcNFc120h0Ep5W5UcJ0CcBOAnQCSWusDZ98HYGCxz1tYWBx5HNLLrrWuaq3XAxgEcDKANU/xEQdKqU1KqfuUUvfVzEgDCwuLpuHPot601kkAtwA4DUBcKSd8aBDA/kU+c5nWeoPWeoPLbZk+C4sjhaf02ZVSXQDKWuukUioI4GzUN+duAfBqAFcCuADA9YsfpQ63x41YozbZ3JzMwuLUmJnNVthPtAUXmTT9k1i7DPvkSCfJDw0EiLa4+mqZsXb55d932ied9BzRx8N2v/PN/3Dabsh5XHfddU67apTuXTJAIb7j+x4TfW0x8sm2PUiU3dzknWJcXwddS1dC+p7ZOdrf4BGVBeluI9bGxAuj0t9GmHzK5BTRXD6XpNeCXqrF5jFqj3E/HTVan0pZWnclltnm9svMufl5CmHt6abw25kFuaYZVjfw+1f8RPaVyRcPttF9L5flgtT4ZoJBm5XZXlDZEFapsLJq1RrLzoRcDx+7NrNceYVRdrUa9fk88rniobk+SAowHqo/V27X4q/0ofDsfQB+qJRyo24J/Exr/Qul1OMArlRKfQbAgwAuP4RjWVhYHCEcym78IwBOOMjvd6Huv1tYWPwvQHMj6KoVzKTrEXRzaWnGH3UUlUPevl1mcnV3UaRWiWlz14rSnON636aJP7/AMumYqbNx40Yx7m1veYvTLhbNMsT0uVSGzOd5I0tq2cpjnXY4IGnEO+/4g9NWNfm55x5zptP+3mWvpXGlKTEunyZtdG+HjKTi4BW2ivJUcLGINK+WohG1Cl1nfxeZu8nUQ2Lcri3kUh174qmib3aKzN1EL5mcWeOe+aNkBk8v7BF93hDNYzLF7kVIUleb/uUddIySzJgsBGkeRRc/t7wv6RyjGCPSnWhvJxcitSCfiWmWTegBrUc0LCNEecba9t0jom8l08SvVcjtCBtl0Ho6SOv+5S99g+jr8NT7PEb0H4fdMbOwaBHYl93CokXQVDO+qmtOtcnuXllaaccuMt0jbVHRN88qldaYQEBnu9wdzjMTrpSRu9SRNjKx/H4ym/7whz+IcZsfecRpixJGAGIxmtcn//VzTvuEtc8T49riZEplF2R02rLVx9APSprn3/zGRU57dM8dTrs9KndeS0yn7KEHZbmjE46nOZayZHLGE4ZGXJCtsVdWT903TbLbMzWaY7xXRm3NzTKTWcs5RqLkejELGfFOufO/Y/9up71kUIo17J3b57THJuhcl39f7riPTVGiUDAh5zE0MOy0H9v8gNNuNwQ7YkymuVKTUYljc3R8lzZM/G46TiZJfTt2yQSlSIhM8uHhYdHn9TGZaTc935WSfP5e+QqK1BzoWiH6ujoaEXRea8ZbWLQ87MtuYdEisC+7hUWLoKk+u9vlckoRh4JSoHDBRVlqbiM1qsiEF7jP/ielb1npps52KUbJRSY5pWZG8qFG9N0nPvGvouuA8AYA3HvvvU77kft3i3Hvfitl+wZDkj7RbM6lrIwmO/HEc5z27b+j6ONdI2NiXE8nUWWrVnSLvkk2R84uZbLS/0vlxp12R0L60TtH2V4Cc+fLM0b0W4k+l8/Ie+EN0j1MM+18v5b3NhCkY2zbs0303fALEvXcuZv2JibGZ8S4vh7au8lrw9/eS/dmoI8Jl84bJaYLNMcq5HW6mNi9Nso5p9IknFopk7/c2SX3nWq8hLNLRtAVCvQ8clGX8f1yT+eaa37utGcmZOTnxjP/DsCfCrly2G92C4sWgX3ZLSxaBE3VjfeGvLpzTd0uXEjKSKehoaVOe2RkRPRFWKI+N9W1QYPwiCNdkdcVClGkWdBP0XVc0w4A3Ez3a2BApujv2EH6bmed+bdOe2KfFMq46Vc3O+3xUakJ1hkhasgVkEkVKLFyUOURp/k/V39VDIu1kZ79yG5JHR6zjihNv4cixlJJad6GQuQKuCBdqmWrSUv/vsfItE4XJdV53LFvctoDS/5W9Ckf6dXNZ2keE3MySi7RS+f+8EXvFn0lXhnWRc/Ao4/LCMv+ZVQpN9IpIyf3zz1Kc2L3tpQ29OuZq1iuSbEUn4fmUatJMz7DIvtcVXrGOuJSYCOb4W6qvO8+H/1cYPr1vIQWABSzLjZORk6qRmLM2J49KBYKVjfewqKVYV92C4sWgX3ZLSxaBM0Nl61UMDdTpwZKJUl9VJmYXtCop+Vl6Vv8r1O5JP1yD6PsPH7pk6WZAGWwm2g5sybczu1b6fhlmaG1bt1ap81LD//wR98W45i8N+ZnJX0SDpAvV9gvab+OTkbXuGm/4KRT/16Mu/duomDa2k8Sfdki+ZRLltMxfvv7G8S4QJB8w9Ofv1r03XDj/U5bBWm+ic5VYlz3AK0HPPKeZVjNslSW1n7f+C4xLl2mz33coDq5y64rtDab3n6hGNcZJ7rq3oekwGe8l9ajUCL/2u+SPnVHB+1HpFPy2UymKFw2aui1D/SS/nxqnvz+6SlJl3J6MJuR+ydu0PNd4/tQLrknFUsQD/rRj35E9HV21MOT37VJrg2H/Wa3sGgR2JfdwqJF0FQzXoPK5SxfvlT08fLIy5evFH17do04ba5h5nZLU51H1BlWPNraiGqanCSzLNEuM61OPZVEGMzyO2vWkKjuO9/5TqedLcqIrulJupb3XfgB0Xf/H8lEfu7Jp4i+/772aqddKVDEW+fSDWLcVR+mMsTHHtsv+s5aRqJCV1x9I839+L8R47bvIHfl2l9uFn1tCTJxu8KUXXXCc14qxnmYSwKPpInAtP87+8j87F4irzlXJporYGRs8ai/RJhKUv3kR7Isl6+NHuMLNkkN/72zDzvtgSFaq91bJb2mWaBjpSzvezhAz0jIJ92VQpai4Vya5rFymXSN5mbomSjlpJuAKjFlB8xxANjFnnsAaIuSWT+fNqIIB+ufM3X5Oew3u4VFi8C+7BYWLYKmmvEu5UIkUDf3wn6ZIJJ20e6tx7BFSsykLbPSni4jEolHyc0syF1wXq31yUrkpLKkKXbeeeeKvpUryb0IR+gYVS2FMh5+jIQnZhdkxdGVa2mH/ObbfyvPPUu7822Dw067lpYCFT+4+lanfddtvxJ9/3nVD532he/4kNN+93veKcadddZZTnvN8bI668azXuS07/wjRaAVqzLpZvcoJV24/UbJLuZSxTtp7fMlyUB4vOSWxaKysmo4QDvw6TTtYIeDckd8YpLWWFdkwo+HJbUEvWzXuyITd/jxlVF2qT3OzHi/dFdKLBFmuJ/W8eV/9wox7pvf+HenHQnIdQyF6TXMsgg6v09qA/YzN+Q7l39D9I2P1xObUqNGVCaD/Wa3sGgR2JfdwqJFYF92C4sWQVOz3tx+lw731akLs4zOQB9pYqdSMiMumaQILMVq/JpliAeHiJ6JRKS/k07TMWuazm2K/+3aRZltYSNaamGB/LprriXRw3/92PvFuDtup7JOJxy3XPTdctNtTrtsUDDxCFFURRaBFvLJrZVKmfYIvBFj/0HUeWIZWm4ZjQUvUUipabkn0BanCEOu0583IhaDbTTOZVBvo9OU7ef20XX+/L+uEONWMAp2xfBRoi/ko8i4SIj83LmkzDJ0s+zB885/kehr62bCGWytijk5X5+H/PK5GbnfU2VrMNA7JPp6EkSVrV1N9QI2vuAcMe6qK37mtB9hoqYAEOugPY3tux532gsZeV9cbB2zBRmF97o31OsMXHHJrzA5Ovv0st4aZZsfVEr9ovHzMqXU3UqpHUqpq5RSi+96WVhYHHH8OWb8uwE8wX7+IoCvaa1XApgH8MaDfsrCwuJZgUMy45VSgwB+COCzAN4L4GUApgH0aq0rSqnTAHxSa/23T3IYeAMenRiqmyyRNqlBzrW9zASUWIzMuUCAzM/ZWam3xfXkPAa9xum2YIgitdyGeas1mUpthn49ryBbqRJ1Mzcno5mqbP7f/Maloq+7kxIiOhNSJ0+z+vXj+8gMvuduKVAx0E+mIxfUAICXvvglTjsUovl7PdIlae+k6De/X14naswKdNF6pNLSdNRMa33LTqkf953v/j+n/dDmu512pM3Qr2fJHsWU1Gbraiea0u8lWi65IN28XIWi4bwR+ewgQCZ/rkQuTiopn/uOBNFa2QVJpb7jrZRcsqxfumXpJFF91Tyt27IhmTR0+21UlbdvQLoCgTCFeyovuSRveKOMBgywKr8uv6QOL/rY+wAAX3zvj7B3+8TTMuO/DuCDICewA0BSa8f53Qdg4GAftLCweHbgKV92pdRLAUxpre9/qrGLfH6TUuo+pdR9XBnWwsKiuTiUCLrnAXi5UuolAAIA2gBcAiCulPI0vt0HAew/2Ie11pcBuAyom/HPyKwtLCz+bBxKffaLAFwEAEqpMwG8X2v9eqXU1QBeDeBKABcAuP6pjlUpVzE9Wfezs1lZA82lyHfr6JB1uPi+Aq+/xsUnAam5nUxJeoZn1fmz5CNxHx0AvMwPDYak369cNI94hPztvLwUXPcrWoqZqQnRxzPzglFJDz62mSiZ159PghXd3XI9JpkG/qpV0jfsGiAKMxEn8cllS9eIce4gyx7MmzXtiJbi5e5CUTmPGRbG6wvLNMN3vY/83Ne/4RanXV2QlCsPje4xRBrzefKdq0VyQ4MBeV/KJeqbmp4UfbkK7af4gnRvvW659vv2kqhGZ1wKa64apjDp9rBcg+0P3em0Tzvp+U67WJD7D6eddJrTfuzxraKvlKfr6R5kGYKsVDkA7J2ifZFlR8n5f/8HdQGV2Rm538DxdIJqPgTgvUqpHaj78Jc/jWNZWFgcZvxZiTBa61sB3Npo7wJw8jM/JQsLi8OBpma9QQGehi1RMsycCmNMOhKSOUgxjXlOy5kUTG8vmYFDhub72BhpgnkDZHIuLEj6LsfKHEPtE3379tHPbREyka+75hYxbn6aDKY1K08QfckU0YM3/+53ou/d73qL016xiiLLFhZmxbhwO5nZ6ZKkw3589Y+ctpfpwr1l07vEuGVryPzPZeW9yFXpsfD46F5UIGmtTJGorHxR+jK9XWTuRuNE7cWM8tMRlkU2Oy6vszNBUXN+N5m68yl5zTVGg3Z3y4yyVIHuxcQUbSt1tkvq96iVtB6nnyKFPlAl1yO7ILP2Ttuw3mkXmFsTDMjjT06SOxENyNeurZPWKs+ev/lZ6Yoev47KfWeqMptyarr+LpQXT3qzsfEWFq0C+7JbWLQIml7Fta2tLlpRMRJhUqySpblTn8mwXVm2A1/OGGZlhMxKf8Ao78Mqt3r8rCqnluV8eOVTnnQDAG43/czFMPpYEg8AxKN0/O27xkWfm5Vkev/7Pij6/MEAa5PZWjGkjQMhVkLKI/9e7xuj8kopFgn2y/+RZIlm+npDTCgDANauovJP3FS/6Xc3iXH9g+Q2zWdlFOGXLrnYaZdK5CZ0d8tzje6iXfBCQe4kb9lKCUU+pjfY2SNNdV4Jdj4rTfwyY3IGB0hPz1U1gsyY7txL/vYlois3R+7iIw/dJ/rO/TsaO1YiJiCdlKyAW9EzsWypjKCbnGMy5+zefvmLXxbjPvOVi5x2J9u1BwBXI/Juxi0j68SYRXssLCz+qmBfdguLFoF92S0sWgTNFa/wunQ4Uc84Ux6Z/ZROM7GGkKRnqqz8sot9LpeRPl44yiiehKQ+ZpgggY/5xpm0pO+43sPgsIzo4rrjy4ePdtpf+eJ35TzY/C//3vdE3yXf+BI7lUFX9VEEYLVGvtd8SvrDvJQVL1MNAJEIXXc2Q/sUCwZNyT9n0lUrVhAN9egjpCm/fKXM+JqapXlVtIzCK5fpZ66/nzMiG9eupnON7twp+pYuob0QxXTo943L0kpBlo149LHHiT7tJX9+5w7aH/AZ21X//A//12n3G5Fr3QkmfDkro8JHd9P6JOeIml0yNCzGzU7T/Vx/4lmiL5miLMySpmdHheR38c79lGH+lW9/UvTlS3Xacs89BRRSNVuy2cKilWFfdguLFkFTzXiXW2lPw3rkGu8AoF0sUsug5YKB8EH78kUZ+cVpuY4uqUHOE164kVNilT0BoFAk16C9XdIbQ0vJrAyHyOQuF+TfzAcfoJJD+ayM0OsdJJP56LUrRF8kStFkm5+gY2QyGTGOuzX5vFyDDpYMNDhI852clBQgFPkrXBAEAIJBMiu52xTvSIhxu3aPOO2lS2U5L/65Jx4jXbUl/TKyMcUER7piUkQjy9auXDg4dQoAvjC7Tz5ZQgoeOqbHRX21rJH846fn8cuf/6zo27n9Qac92CMp3d/ddCUdo43WNBQyy2FR4kp74mjRFY5SZFy0nVwlb1S6oh/8BGkdLpRlglUyU/95552zyC+UrRlvYdHKsC+7hUWLwL7sFhYtgubWenO5HFrN65W+D6eMpg0dcx8rk5tMEoXm9S+uXp1MypK8PT2UpVYok5/b3i59+2qNfDyX8aeQi1OO7CEBgq5OeYyBIfpgqSr90EiU+nIlmeU1P0Z+5MQEE9swdOMTcfL7Q0EZSsu1ODJpCs2dnJDZWjUWJtwel/6lv5/WimeUpTPyXAssy2tqVt7Pdpaxls8zf9sj71mciYnyum8A0MH2CCol+ly2IPdZNMvGCwXlPkuZUVnZFK1vV1CKfX7iIxSKeu/dMiT2vJc912n/7qYfiL5QmOaSLxL1tmu3DJddMbzWaVdjskz40BCVCd8/RWt62y0ym3LJEIlo3HL3dtGXa2jbV59E+s1+s1tYtAjsy25h0SI4AmZ8neIw6TWPh6bCs6QASZtVC/S5UESan0EeTeaWf8c6eslsm5ggGsoTlOYnj+urQZqVgSjRM/lRin6bS0oax8cOGTDmyMUyOMUFAFu3UsYaT7jjuvn1z9ExQ8b8pybJfOTryPX5AMDl5ul9T1Lml01kYV7SiF1dzBSuSfNxx3YyM/m5zUzCrl7SeysXZJTfNBObqGkmUNErNeJcPlqPqTkZlVhiwhMJpnFXzcl5XPjO9zrtr//bp0XfFT+iUl9BvzTP/V6micj07vwGA1gqkdjEnhGjr0huUyhKGYeveJnUjd89Ts9tviKjR/9w7+8BAC4laVoO+81uYdEisC+7hUWLoKlmfKVSwex0fVfYlIvev5/KHZ155hmi7/Y/3u60Yz1kqntMLa8OilLq6JHHT3TQLm2km8xxl0eaczyCrlCWQgDpKpmZuRqZb+V5acZHAmRWHj20TPSVciNOe89OmdAxPEQRb+PMZJuakOzEcceRGcultQEgxIQzSlVm0rmlqb6QIZEHM1KQV27lJa/yeenWeDS5ENms3CEPB+k+jY4Sg7Jq5UoxrlAlV8NrRFVOsKQZP2NeqklpwoYidA+ThnhFjFWkzeXJDTl5zfPFuLd9/t+cdtB4K557Kj2P//Gt94i+Y46hc8dZBJ0RmAmwe9EWlut4zCoWSemhCLrZaXkQt6bne8XwMaLvuhv+GwBQLhtiLAz2m93CokVgX3YLixaBfdktLFoETafeDogmTBh+aDRGPt5d994j+oaGSKBv3wTRMZGgLIEzNkU+sDaisXIV8n+8LGsqEJYZXwGWeRYPSV9WHC+3xGmPbhkRfVOT5GsG/FJ7Xrvo3LE2ua+gWAmsIPN5QyFJa3EqUit5nQUmEOln/E+xJCkpLp7JaU8ACEUo6q9UpOMHfTIa0M1KZbndkgKMMl9/ZoaVYDI4qXKFfPb5lKTeBpeS/8pLcM/NSzGP8SmKNgwbVKeflaXKTNMaPPSIrFP6m5t/67RfcY6sPN4WJerwgv/7ZtF3331cp5/2HJYMSX+7lGf6+NMGPabp2vw+eqZjHhmZ2cMoWBWSezW//GXdZ3/Tq/4Ji+GQXnal1AiANIAqgIrWeoNSqh3AVQCGAYwAeI3Wen6xY1hYWBxZ/Dlm/Au01uu11hsaP38YwM1a61UAbm78bGFh8SzF0zHjzwVwZqP9Q9RrwH3oqT5Uqx7897y6aSkvB4XDZN7x6DFuHgJAsUifm/HLvlCJjr90GZngPLkFABSLoeOiGQBQq5FJy12L/Iw0y+ZrlHQyybTvACDA5h8wTFo3W5xIG5nMXPPe7PMUJQ2lJ8jk56ZvwaieGmCVUE3FMm7+lzV9rlSSxxjfR25TLifXYO2xFAlWLNC6mYkwfE39fulScRH/IqsPFvBLii7F9Au5sAcAZJI0L63pQh98VCa7fPvSf3fa8wsyieqE44932pGg1NC75hq6N34/uWUul6RtywVmxs9Ll6ez6yinPc4e2x37dolxFR9d297ZR0Xfpd/9KgBg3x4pasFxqN/sGsBvlFL3K6U2NX7Xo7U+QAZPAOg5+EctLCyeDTjUb/bna633K6W6AdyklNrCO7XWWnEJUYbGH4dNAKBcB1XLsbCwaAIO6Ztda72/8f8UgOtQL9U8qZTqA4DG/1OLfPYyrfUGrfUGl33ZLSyOGJ7ym10pFQbg0lqnG+0XAbgYwA0ALgDwhcb/1y9+lDq01k7J5Q5DNILTONM1ScvNztImf5yFvRaT0rf3ttMxigVZBy7ARB5iUTpGVRs157Lk47kM9QouaBkJkT8/ZYhtuJgTXCoZ4hJsxSNR6Xt2dJPPFwlS3+iY1CqPsRLI3oL0/7zM345EiMaZmpZ/i3n2mZllWGbX2RYnuieflX5oYS/Riny/BABiEaLe2tgeQzQsRRQ52WaG3PJ7MzNL9JpZn6/Ayn+bQqbz8xQ+W8nTM/Hc0zeIcZ//0qecdmpK0pTf+jpp/U9NyDme96q3O+2rrqSQ284OeZ0+Dz1zGzeeJ/pGRumZS2bJQE50yHfkoe1EF87mZah1oqt+38c9i3+hHooZ3wPgusbD4QHwE631r5VS9wL4mVLqjQD2AHjNIRzLwsLiCOEpgz3FPQAAEOVJREFUX3at9S4Axx/k97MAzvrTT1hYWDwb0dQIOigFd0N7LmDoand2UnZSMi2pD26acfokmJBUTSROplPBSDvi2lxFpjev3NLsYUwQymVpmvIMM16CVxuWk8tH5n/IyMzjZalCEWlyVpl5ms6RKblgrEeezaNYliZ4pUamKgvIg8u8TlYvoGiY8dys37Zvh9MO+OR6e1g0YDgkacoKy77ipaO3bNkmxvFrM2sYLBkmetPnpXOP7tsjxqXSvCS0LGWlFPVNM436VE7Gf23bQpqC117xCznHHK1pBVI/7tj1L6b2uhPpeNufEOOqZXKvNpwsS0JPT7FMzhlylaZSUqNwaDlp7ncZWYy/vq2xxspmvVlYtDzsy25h0SKwL7uFRYugqT47p95cLhmmOjpKSjWJhMwGm0uS77JyiEr8jk/J+mUe5qT6PEZ2FVNfmRwj0UBO5QFAyE97CV6voUvPKLVcjvzQ446TZYL37CGfUtekb+VlIaz5oqSyeJhmhWWDmSG945MUEmnSZlyjne8xmJltXPDT55PXKbXHFRsnffYlS4axGDjl6GbfKfNzUkkGLBbLbcyR74u0x4iG4msPAF4PhbBmjTLeukbn7u+nfaFSxQhBjtF9T+VkSGzVQ/ssS5evE33KQ8cvlMhfPnrdoBiXZZRaKiOfzQkmktnWSaKY/3jhm8S493/8LU47o6U/XyzX6TsefmzCfrNbWLQI7MtuYdEiaK4ZX9NOdtsBc/4AZqeIFlm97ijRNzFK5jrPejPNW262cvMKkOWmeKRWW0Ka8ZqZ6tmUzOTixyixUsmGRL0QcwwYrgCP0PN75fzDLKKuWiVTz6ST5hiFxM12QApgcHM8FJJCHwsLNEczE41TYB4XXfO0ITjiC5JZb+rBj7KMOE5hTk1J85Nr569YJUtYl4rkargYzdfR0SXGtbeTeb5v317Rxz83MEgm8uy0jECbHKM19QQkLfyqV5/vtH9+5dWiz8NqCwR8dJ2F/dJdCQfJDZlPyojIoWEKYxmfprS3z35Z6te/5V2vddrBdin0UVEHzPhF0kphv9ktLFoG9mW3sGgRNDmCjnaFMxlphvCZZDLSfI4wPfiJCdqJ7mo3tOdZWSevYVZGorSj6vOR6Rjwyh3mDNvNnZ6VySM8yo/vghfyMnGCm8GJTjlH7r74/TKJpbuXzMxpVsYplZK7w9yV4ck5ABAOU9IJd3O4ph0gq9xyU7c+f1o7Xl13bFQKIyi2VjzpxpxXb0+/006n5X3P5YiRqBoRi4ol9WhWXmp+Rka/8Uq8/PoBuTs9zVyIoF+uRyxG4z780Y+IvkCY3KtNb3+b6HvFuS932s87hSLotu+QkYJnv4Ci5qpuuQab3kG6du95P5Wh8hnRl+uOJybg/kd+LfpUw4V4ks14+81uYdEqsC+7hUWLwL7sFhYtgqb67MPDw7j483WRgDe/Wepvd3TxksqSFunt73Pa3A81BSe5UGIgJKOUpqbI/26LU+aSLyD9Zi58GTaEEPguAPcvFwyfmgtxBMPyGLUs+femf8l95blZ8qn7+/vFOA/TaM8ZghKcOvSzaMCkEbnmYsKahZzUIH9s5076gTGkkaikpPj+g+mLBwK0F8Kj9cz9hw2nkogEv0cAMBxZetBjBALGfWF0Y6JNlqZOppmGPxMQHR2RmXNdXfSMeQy6NNFNewJT+2XJ5ksu/ZrTPu/Vv3HaH/209Ps3vuhsp+2Pye/Y4zasdtr/8oF3OO1/+9rnxbh8lvZIYhFJP6bzjXdBP0n57UV7LCws/qpgX3YLixZBU834Wq3mRHx1dEpzi+ue1apSxIBHxhUKZMpUDS0yZpkim5f0XSBAZr2HJeGY5m04TKZqLi2TKsoFmoeXmf9m2eQDJa4O1ifnJGm/+XmilDgFaNJmnNYKB6XWGU8SKWTJzC7kZcJMLkvmXsSoURwIseQXRevBSzkDkmKsFOTxOQfEXS+/oZVfyDDqzaARU0lyDbgeXck4F9cK5FGOgJHkww6fnJfuz2A/zatUlvdskiUeuf2S0u0eoOjGPeO7nXZHr3y+d+4nKq6vd4noyxQpMjGZoXNd/Ol/FeOSGaIOvW7DlanU569gE2EsLFoe9mW3sGgR2JfdwqJFoEyRv8MJr9+r2/vrvszUfplB1dlPPk6pJP0pP6NapqfJb4nGpN8SZYKT07OSluvrI2olGCEfeGxCZiD19FAVq/37ZR8vc8yFIxcykk7q6SM/rmJk9/FQ14GBAdE3MjLitGdZaOdJz5Ea57feeivNIyoFELlIRU8n0TOmqMHevZQdVipIH5UPbY8RJbowbwhPMOSMPYE2dm80C102S0zH45R16PbLLEAegusPMtEPI9MvV+D7G5Ie9PlYLQG255CckyKevd30fPB6f4CkC6Ntcv9kZIRoymNYtmYqPSfGLbC9oTe/6S2i7957HnLaTzy+3Wl7vXJ/Ixqm9di1W4bjzs3V51hLArpsSqDWYb/ZLSxaBPZlt7BoETSVenO5FAINmieckFFKnHYyPYt4O5n48QSZUV6/PEYmRaaZzyMpmBrTggv6qM8sR1mrED9juhOcUuOZeRlD98zHriVr0He9LLONR8kBQC5F5mmY0W0TYzLbrMxYxbJXuglzaTIXcwt0vFhMmvuaWd0+t6QAE50HL/nU1iZpPk4rci1+QLpNs7OMWkrLDMEFF90AM1JQa7oXQVbO2Sz/NMtctmpVrgefcyZFaxMyaM90ku6ZmQVYqdKzky9KC5m7JX+8i8zx1auliza6l879hS9/SfT1dJLryHX3TL2+QobWbvUyKfDyYLJ+7gKeZgSdUiqulLpGKbVFKfWEUuo0pVS7UuompdT2xv+Jpz6ShYXFkcKhmvGXAPi11noN6qWgngDwYQA3a61XAbi58bOFhcWzFIdSxTUG4AwA/wgAWusSgJJS6lwAZzaG/RDArQA+9GTHKpfLmJqqJxJwIQgAKFXI/EqlpHk7zSqQ5pNkprgj0iT0++lvVyAsxRTmmRx1op1MWnN31eOlYyTiUp+Oa8FxYYuEYd6WWAVZt/H3NMB2WNNJuYvvZ0IaHR0kerFj+3YxLhgi9yXgk7vPC3lyG1Jsl9oU6agwqWdzp74UpPmXy7Teppk9wcRCTNeLzz/NXIuKEVDoitL6mHLXWVYCi/fVjCgxHkHHzX0T/BlY0jck+nhUpdstXcC5feSGTE9Ld2XpsmGn7WXuSrki7/vKNXS+rCHOwhOAsvO0kEODsorrxH6qmuupSndi/dF1OfNH7pdlpzgO5Zt9GYBpAN9XSj2olPpuo3Rzj9b6wN2eQL3aq4WFxbMUh/KyewCcCOBbWusTAGRhmOy6TtYflLBXSm1SSt2nlLqviZS+hYWFgUN52fcB2Ke1vrvx8zWov/yTSqk+AGj8P3WwD2utL9Nab9Bab1CL14m3sLA4zDiU+uwTSqlRpdRRWuutqNdkf7zx7wIAX2j8f/1TnszjRqK97t8ql/ya59QYj2IDgCVLKEvI7WElmIxIqulp8pm0S/5lmZwk/49TRrGIFJDgGVqcagMAL9N555GHpi87PceEDX0yCoqXtpqZklGEPPorHKQ9h+yCsTfB/G8z2ouXaQ4wijFsZM7VmM9uUofpBco241lkZsYaF900hQ7zTISTr5VLusOIsFLPJtWZnKV1THHaLCz9ci7caVKMxTIdM5ejeSiDoirzUlxG5FqcRUsWp2VkXCFPxymyx3F0Xn73rVg+7LQzaamdH2OCGwPddO7REVnezMv2JgIGtZxdaETQVRfXjT9Unv1CAFcopXwAdgH4J9Stgp8ppd4IYA+A1xzisSwsLI4ADull11o/BGDDQbrOemanY2FhcbhwBHTj66aIy9gtCEfIhM1mpZ7Z5scecdqxGJnd0ZikvPoHKDpt35jUseMJEWlWLTXSJs14j4fmoSsyGmtyjMyqMjNhcxnpTvDSUCG/TNYpMOEF03yulOh82ST1VXLS5elZSmafG0ZEF7Pi8jk6XiYlXQHFtOp4hVRACnMkk2S2pheMiC6m1xcKSbNybIyXf6J5tLXJ9eAmfjYr58gpwRrToDMTYXzMvSiWjHvBzs0eASTnpAtVZnRp0QhCGxikaLjOhKSMUyxKEZrcC7eS67F3hM7XxSq1AkCeiVJML1A0YMKkhTVdwMKcdCeOXrMWADCySz73HDY23sKiRWBfdguLFoF92S0sWgTN9dk16X+bQowhJihhlv/llEypRP7ZmOGX87DDTE76w/yYM0atMI7F9M7rx6fPxTvI1zd9TUE1GRlUXFTRZfjbXCQhWaZ9BU9I0mt5lv1kilZG2TpyKq8tJPcm+Jw5hQYAGSbGUa6RL2vq9JfLdJ0dHZLymmJjQ0zDvy1hCmRS6Kgyal9z6tMbZOWyjflmc7THo6cl9eRlgpORKN2LWFSGU8cHaX22bJVln8eZwInHLUOoa4qurSNO4dTzCzIU2suuLZuRz37Ax565AstUjMq1yjIBTp9P3vdy433iNfFM2G92C4sWgX3ZLSxaBE3VoFNKTaMegNMJYOYphh9uPBvmANh5mLDzkPhz57FUa911sI6mvuzOSZW6T2t9sCCdlpqDnYedRzPnYc14C4sWgX3ZLSxaBEfqZb/sCJ2X49kwB8DOw4Sdh8QzNo8j4rNbWFg0H9aMt7BoETT1ZVdKnaOU2qqU2qGUapoarVLqe0qpKaXUZva7pkthK6WGlFK3KKUeV0o9ppR695GYi1IqoJS6Ryn1cGMen2r8fplS6u7G/bmqoV9w2KGUcjf0DX9xpOahlBpRSj2qlHpIKXVf43dH4hk5bLLtTXvZlVJuAJcCeDGAtQDOV0qtbdLpfwDgHON3R0IKuwLgfVrrtQBOBfCOxho0ey5FABu11scDWA/gHKXUqQC+COBrWuuVAOYBvPEwz+MA3o26PPkBHKl5vEBrvZ5RXUfiGTl8su1a66b8A3AagBvZzxcBuKiJ5x8GsJn9vBVAX6PdB2Brs+bC5nA9gLOP5FwAhAA8AOAU1IM3PAe7X4fx/IONB3gjgF8AUEdoHiMAOo3fNfW+AIgB2I3GXtozPY9mmvEDAEbZz/savztSOKJS2EqpYQAnALj7SMylYTo/hLpQ6E0AdgJIaq0PZP806/58HcAHAUcMvuMIzUMD+I1S6n6l1KbG75p9Xw6rbLvdoMOTS2EfDiilIgCuBfAerbVIj2rWXLTWVa31etS/WU8GsOZwn9OEUuqlAKa01vc3+9wHwfO11iei7ma+Qyl1Bu9s0n15WrLtT4Vmvuz7AfAyHION3x0pHJIU9jMNpZQX9Rf9Cq31z4/kXABAa50EcAvq5nJcKaeyYDPuz/MAvFwpNQLgStRN+UuOwDygtd7f+H8KwHWo/wFs9n15WrLtT4Vmvuz3AljV2Gn1AXgtgBuaeH4TN6AugQ0cohT204WqJ9VfDuAJrfVXj9RclFJdSql4ox1Efd/gCdRf+lc3ax5a64u01oNa62HUn4ffaa1f3+x5KKXCSqnogTaAFwHYjCbfF631BIBRpdSBEq0HZNufmXkc7o0PY6PhJQC2oe4ffrSJ5/0pgHEAZdT/er4Rdd/wZgDbAfwWQHsT5vF81E2wRwA81Pj3kmbPBcBxAB5szGMzgI83fr8cwD0AdgC4GoC/iffoTAC/OBLzaJzv4ca/xw48m0foGVkP4L7GvfkvAIlnah42gs7CokVgN+gsLFoE9mW3sGgR2JfdwqJFYF92C4sWgX3ZLSxaBPZlt7BoEdiX3cKiRWBfdguLFsH/B+BvqS4iN2uTAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"dgkAYOW5vqzB","colab_type":"text"},"source":["Many software bugs in deep learning come from having matrix/vector dimensions that don't fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs. \n","\n","## <font color=\"blue\"> Question 1\n","\n","**문제:** 아래의 값에 적당한 값을 할당하시오:\n","- m_train (number of training examples)\n","- m_test (number of test examples)\n","- num_px (= height = width of a training image)\n","\n","**hint:** `train_set_x_orig.shape` = (m_train, num_px, num_px, 3). For instance, you can access `m_train` by writing `train_set_x_orig.shape[0]`."]},{"cell_type":"code","metadata":{"id":"PK50_h6B1dpG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1595221511032,"user_tz":-540,"elapsed":1126,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"390d4588-691f-4297-8c73-b16cf4e3d2ba"},"source":["train_set_x_orig.shape[0] #(데이터개수, 픽셀값, 픽셀값, 채널개수)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"7GVSO9-WvqzC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"ok","timestamp":1595221820995,"user_tz":-540,"elapsed":920,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"c90882cc-b6ff-4f2d-9fdc-895c27765129"},"source":["### START CODE HERE ### (≈ 3 lines of code)\n","m_train = train_set_x_orig.shape[0] #training 데이터개수\n","m_test = test_set_x_orig.shape[0] #test 데이터개수\n","num_px = train_set_x_orig.shape[2]#세로(height)픽셀개수. 가로(width)픽셀개수인[1]도 된다\n","### END CODE HERE ###\n","\n","print (\"Number of training examples: m_train = \" + str(m_train))\n","print (\"Number of testing examples: m_test = \" + str(m_test))\n","print (\"Height/Width of each image: num_px = \" + str(num_px))\n","print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n","print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n","print (\"train_set_y shape: \" + str(train_set_y.shape))\n","print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n","print (\"test_set_y shape: \" + str(test_set_y.shape))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Number of training examples: m_train = 200\n","Number of testing examples: m_test = 50\n","Height/Width of each image: num_px = 64\n","Each image is of size: (64, 64, 3)\n","train_set_x shape: (200, 64, 64, 3)\n","train_set_y shape: (1, 200)\n","test_set_x shape: (50, 64, 64, 3)\n","test_set_y shape: (1, 50)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_B1JiwkwvqzE","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**: \n","<table style=\"width:15%\">\n","  <tr>\n","    <td>**m_train**</td>\n","    <td> 200 </td> \n","  </tr>\n","  \n","  <tr>\n","    <td>**m_test**</td>\n","    <td> 50 </td> \n","  </tr>\n","  \n","  <tr>\n","    <td>**num_px**</td>\n","    <td> 64 </td> \n","  </tr>\n","  \n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"pxdxxHV2vqzF","colab_type":"text"},"source":["### 2-3) data preprocess \n","데이터 전처리\n","#### 1> flatten\n","\n","image dataset은 4d array, 즉 4차원 배열이다 (200, 64, 64, 3)\n","\n","image 자체는 3d array이지만 이를 딥러닝 모델 안에 넣으려면 1d array꼴로 만들어야 넣을 수 있습니다.\n","\n","그래서 (num_px, num_px, 3)에서 (num_px $*$ num_px $*$ 3, 1)꼴로 만들어야 합니다. 3주차에 배운 numpy 함수로 구현해봅니다."]},{"cell_type":"markdown","metadata":{"id":"Wi0oAactvqzF","colab_type":"text"},"source":["## <font color=\"blue\"> Question 2\n","\n","**문제:** training and test data sets을 reshape해서 images of size (num_px, num_px, 3)가 (num\\_px $*$ num\\_px $*$ 3, 1) 형태로 되게 한다.\n","\n","**hint:** A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$*$c$*$d, a) is to use: \n","```python\n","X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X\n","```"]},{"cell_type":"code","metadata":{"id":"H9EOW00ovqzG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":92},"executionInfo":{"status":"ok","timestamp":1595223527698,"user_tz":-540,"elapsed":1033,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"807de8da-14a3-44ad-ab41-4a81a0d57a1a"},"source":["# Reshape the training and test examples\n","\n","### START CODE HERE ### (≈ 2 lines of code)\n","#(200, 64, 64,3)을 (200, 12288)로 변형\n","#그 후 feature가 행에 오고 데이터개수가 열에 오도록 transpose\n","#(n_x, m)형태로 변형 가능\n","train_set_x_flatten = train_set_x_flatten.reshape(train_set_x_flatten.shape[0], -1).T\n","test_set_x_flatten = test_set_x_flatten.reshape(test_set_x_flatten.shape[0], -1).T\n","### END CODE HERE ###\n","\n","print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n","print (\"train_set_y shape: \" + str(train_set_y.shape))\n","print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n","print (\"test_set_y shape: \" + str(test_set_y.shape))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["train_set_x_flatten shape: (200, 12288)\n","train_set_y shape: (1, 200)\n","test_set_x_flatten shape: (50, 12288)\n","test_set_y shape: (1, 50)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nXJtbK_UvqzI","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**: \n","\n","<table style=\"width:35%\">\n","  <tr>\n","    <td>**train_set_x_flatten shape**</td>\n","    <td> (12288, 200)</td> \n","  </tr>\n","  <tr>\n","    <td>**train_set_y shape**</td>\n","    <td>(1, 200)</td> \n","  </tr>\n","  <tr>\n","    <td>**test_set_x_flatten shape**</td>\n","    <td>(12288, 50)</td> \n","  </tr>\n","  <tr>\n","    <td>**test_set_y shape**</td>\n","    <td>(1, 50)</td> \n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"ypl99wNyvqzI","colab_type":"text"},"source":["#### 2> normalization\n","\n","image의 pixel 값은 모두 0~255의 값을 가집니다.\n","\n","경험적으로 이미지 픽셀값의 범위를 0~1로 만들면 학습이 잘 됩니다. \n","\n","좀 더 자세한 사항은 7주차에 안내하겠습니다. 그 때는 이미지 말고 csv파일도 normalize 해보는 구체적인 방법도 배울 수 있습니다."]},{"cell_type":"code","metadata":{"id":"7u4oXuImvqzI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595223542537,"user_tz":-540,"elapsed":837,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}}},"source":["#이미지의 경우 0~255픽셀 값을 갖는다.\n","train_set_x = train_set_x_flatten/255.\n","test_set_x = test_set_x_flatten/255.\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3RDckR_u5uP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"status":"ok","timestamp":1595223558263,"user_tz":-540,"elapsed":858,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"d5bdf1fd-e4cb-41d5-b11a-35a0d84c688d"},"source":["print(train_set_x)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[[0.84313725 0.85098039 0.83921569 ... 0.78431373 0.83921569 0.89019608]\n"," [0.76078431 0.68235294 0.58823529 ... 0.65098039 0.59215686 0.57254902]\n"," [0.84313725 0.79215686 0.90980392 ... 0.28627451 0.25882353 0.21960784]\n"," ...\n"," [0.1254902  0.10588235 0.12156863 ... 0.15294118 0.23921569 0.28235294]\n"," [0.75294118 0.6745098  0.56862745 ... 0.74901961 0.65882353 0.5372549 ]\n"," [0.23137255 0.19215686 0.15686275 ... 0.61568627 0.52941176 0.20392157]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"37IwitAuvqzK","colab_type":"text"},"source":["<font color='blue'>\n","**What you need to remember:**\n","\n","Common steps for pre-processing a new dataset are:\n","- Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, ...)\n","- Reshape the datasets such that each example is now a vector of size (num_px \\* num_px \\* 3, 1)\n","- \"Normalize\" the data"]},{"cell_type":"markdown","metadata":{"id":"cyeId3GvvqzL","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"6iP9L3jKvqzL","colab_type":"text"},"source":["## 3. General Architecture of the learning algorithm ##\n","\n","It's time to design a simple algorithm to distinguish cat images from non-cat images.\n","\n","You will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why **Logistic Regression is actually a very simple Neural Network!**\n","\n","<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n","\n","**Mathematical expression of the algorithm**:\n","\n","For one example $x^{(i)}$:\n","$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n","$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n","$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n","\n","The cost is then computed by summing over all training examples:\n","$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n","\n","**Key steps**:\n","In this exercise, you will carry out the following steps: \n","    - Initialize the parameters of the model\n","    - Learn the parameters for the model by minimizing the cost  \n","    - Use the learned parameters to make predictions (on the test set)\n","    - Analyse the results and conclude"]},{"cell_type":"markdown","metadata":{"id":"gY8ZiLlhvqzL","colab_type":"text"},"source":["----------"]},{"cell_type":"markdown","metadata":{"id":"teNSevddvqzM","colab_type":"text"},"source":["## 4. Building the parts of our algorithm ## \n","\n","The main steps for building a Neural Network are:\n","1. Define the model structure (such as number of input features) \n","2. Initialize the model's parameters\n","3. loop:\n","    - Calculate current loss (forward propagation)\n","    - Compute cost function\n","    - Calculate current gradient (backward propagation)\n","    - Update parameters (gradient descent)\n","\n","위 3가지 과정을 있다가 밑에서 `model()`이라는 함수에서 한 번에 진행합니다.\n","\n","이를 위해서는 `model()` 함수에 들어갈 부품들을 차례차례 만들어봅니다. 딥러닝의 5가지 step을 떠올려보면서 진행해도 좋습니다."]},{"cell_type":"markdown","metadata":{"id":"or2HJxVVvqzN","colab_type":"text"},"source":["### 4-0) Build sigmoid function\n","\n","## <font color=\"blue\"> Question 3\n","\n","**문제:** 아래 식을 갖는 `sigmoid()`함수를 만들어보시오.\n","- $sigmoid( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$ to make predictions. \n","- np.exp()를 사용해서 만들어보시오."]},{"cell_type":"code","metadata":{"id":"tR2RqZavvqzN","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: sigmoid\n","\n","def sigmoid(z):\n","    \"\"\"\n","    Compute the sigmoid of z\n","\n","    Arguments:\n","    z -- A scalar or numpy array of any size.\n","\n","    Return:\n","    s -- sigmoid(z)\n","    \"\"\"\n","\n","    ### START CODE HERE ### (≈ 1 line of code)\n","    s = 1 / (1 + np.exp(-z))\n","    ### END CODE HERE ###\n","    \n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_zmo3tO4vqzP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595159895693,"user_tz":-540,"elapsed":831,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"d334b962-6f33-4f44-f4bf-25a796754c59"},"source":["print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sigmoid([0, 2]) = [0.5        0.88079708]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"umsPoiv2vqzR","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**:  \n","\n","<table>\n","  <tr>\n","    <td>**sigmoid([0, 2])**</td>\n","    <td> [ 0.5         0.88079708]</td> \n","  </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"QD1W8l_fvqzR","colab_type":"text"},"source":["### 4-1) Initializing parameters\n","\n","## <font color=\"blue\"> Question 4\n","\n","**Exercise:** 함수 내부에 있는 주석에 맞게 parameter를 initialization 하시오.\n","- w는 np.zeros()를 사용해서 initialization 하시오. (dim이라는 해당 함수의 parameter를 사용하시오.)\n","- b는 0을 대입하시오."]},{"cell_type":"code","metadata":{"id":"9d1qO7nsvqzS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595225081888,"user_tz":-540,"elapsed":908,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}}},"source":["# GRADED FUNCTION: initialize_with_zeros\n","\n","def initialize_with_zeros(dim):\n","    \"\"\"\n","    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n","    \n","    Argument:\n","    W벡터의 크기(길이)를 의미함\n","    dim -- size of the w vector we want (or number of parameters in this case)\n","    \n","    Returns:\n","    w -- initialized vector of shape (dim, 1)\n","    b -- initialized scalar (corresponds to the bias) - 편향값\n","    \"\"\"\n","    \n","    ### START CODE HERE ### (≈ 1 line of code)\n","    w = np.zeros((dim, 1)) #parameter로 받았던 [dimx1]크기로 weight값을 0으로 초기화\n","    b = 0\n","    ### END CODE HERE ###\n","\n","    assert(w.shape == (dim, 1))\n","    assert(isinstance(b, float) or isinstance(b, int))\n","    \n","    return w, b"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"zV8YHCNNvqzU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1595225084035,"user_tz":-540,"elapsed":910,"user":{"displayName":"박준현","photoUrl":"","userId":"02172139527950414976"}},"outputId":"5b367893-b92b-4b3a-df86-a4592545e892"},"source":["dim = 2\n","w, b = initialize_with_zeros(dim)\n","print (\"w = \" + str(w))\n","print (\"b = \" + str(b))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["w = [[0.]\n"," [0.]]\n","b = 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zicfK-livqzW","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**: \n","\n","\n","<table style=\"width:15%\">\n","    <tr>\n","        <td>  ** w **  </td>\n","        <td> [[ 0.]\n"," [ 0.]] </td>\n","    </tr>\n","    <tr>\n","        <td>  ** b **  </td>\n","        <td> 0 </td>\n","    </tr>\n","</table>\n","\n","For image inputs, w will be of shape (num_px $\\times$ num_px $\\times$ 3, 1)."]},{"cell_type":"markdown","metadata":{"id":"v9tGlzxlvqzW","colab_type":"text"},"source":["### 4-2) Forward and Backward propagation\n","\n","위에서 parameter initialization하는 함수를 만들었으니 다음 step을 진행하는 함수를 만든다.\n","\n","## <font color=\"blue\"> Question 5\n","\n","**문제:** cost function과 gradient를 계산하고 있는 `propagate()`함수를 완성하시오.\n","\n","**hints**: 아래 식들을 numpy를 통해 구현하시오. (이 식을 외우지 않아도 됩니다. 구현할 줄만 알면 됩니다.)\n","- (forward propagation) $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n","- (compute cost function) $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n","\n","- Here are the two formulas you will be using: \n","\n","$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n","$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"]},{"cell_type":"code","metadata":{"id":"n8pz9sv4vqzX","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: propagate\n","\n","def propagate(w, b, X, Y):\n","    \"\"\"\n","    Implement the cost function and its gradient for the propagation explained above\n","\n","    Arguments:\n","    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n","    b -- bias, a scalar\n","    X -- data of size (num_px * num_px * 3, number of examples)\n","    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n","\n","    Return:\n","    cost -- negative log-likelihood cost for logistic regression\n","    dw -- gradient of the loss with respect to w, thus same shape as w\n","    db -- gradient of the loss with respect to b, thus same shape as b\n","    \n","    Tips:\n","    - Write your code step by step for the propagation. np.log(), np.dot()\n","    \"\"\"\n","    \n","    m = X.shape[1]\n","    \n","    # FORWARD PROPAGATION (FROM X TO COST)\n","    ### START CODE HERE ### (≈ 2 lines of code)\n","    A =  sigmoid()                                                             # compute activation\n","    cost =                                                                     # compute cost\n","    ### END CODE HERE ###\n","    \n","    # BACKWARD PROPAGATION (TO FIND GRAD)\n","    ### START CODE HERE ### (≈ 2 lines of code)\n","\n","    #dJ/dW의 약자\n","    dw = \n","\n","    \n","    db = \n","    ### END CODE HERE ###\n","\n","    assert(dw.shape == w.shape)\n","    assert(db.dtype == float)\n","    cost = np.squeeze(cost)\n","    assert(cost.shape == ())\n","    \n","    grads = {\"dw\": dw,\n","             \"db\": db}\n","    \n","    return grads, cost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDYz0f8UvqzZ","colab_type":"code","colab":{}},"source":["w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n","grads, cost = propagate(w, b, X, Y)\n","print (\"dw = \" + str(grads[\"dw\"]))\n","print (\"db = \" + str(grads[\"db\"]))\n","print (\"cost = \" + str(cost))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wj-97yplvqzb","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**: \n","\n","<table style=\"width:50%\">\n","    <tr>\n","        <td>  ** dw **  </td>\n","      <td> [[ 0.99845601]\n","     [ 2.39507239]]</td>\n","    </tr>\n","    <tr>\n","        <td>  ** db **  </td>\n","        <td> 0.00145557813678 </td>\n","    </tr>\n","    <tr>\n","        <td>  ** cost **  </td>\n","        <td> 5.801545319394553 </td>\n","    </tr>\n","\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"O-0Hh0_Rvqzb","colab_type":"text"},"source":["### 4-3) Optimization (Gradient descent)\n"," \n","- You have initialized your parameters.\n","- You are also able to compute a cost function and its gradient.\n","- Now, you want to update the parameters using gradient descent.\n","\n","## <font color=\"blue\"> Question 6\n","\n","**Exercise:** gradient descent 식을 완성한다.\n","    \n","**hint:** For a parameter $w$, the update rule is $ w = w - \\alpha \\text{ } dw$, where $\\alpha$ is the learning rate.\n","    "]},{"cell_type":"code","metadata":{"id":"kNc-4Uhhvqzc","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: optimize\n","\n","def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n","    \"\"\"\n","    This function optimizes w and b by running a gradient descent algorithm\n","    \n","    Arguments:\n","    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n","    b -- bias, a scalar\n","    X -- data of shape (num_px * num_px * 3, number of examples)\n","    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n","    num_iterations -- number of iterations of the optimization loop\n","    learning_rate -- learning rate of the gradient descent update rule\n","    print_cost -- True to print the loss every 100 steps\n","    \n","    Returns:\n","    params -- dictionary containing the weights w and bias b\n","    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n","    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n","    \n","    Tips:\n","    You basically need to write down two steps and iterate through them:\n","        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n","        2) Update the parameters using gradient descent rule for w and b.\n","    \"\"\"\n","    \n","    costs = []\n","    \n","    for i in range(num_iterations):\n","        \n","        \n","        # Cost and gradient calculation (≈ 1-4 lines of code)\n","        ### START CODE HERE ### \n","        grads, cost = propagate()\n","        ### END CODE HERE ###\n","        \n","        # Retrieve derivatives from grads\n","        dw = grads[\"dw\"]\n","        db = grads[\"db\"]\n","        \n","        # update rule (≈ 2 lines of code)\n","        ### START CODE HERE ###\n","        w =\n","        b = \n","        ### END CODE HERE ###\n","        \n","        # Record the costs\n","        if i % 100 == 0:\n","            costs.append(cost)\n","        \n","        # Print the cost every 100 training iterations\n","        if print_cost and i % 100 == 0:\n","            print (\"Cost after iteration %i: %f\" %(i, cost))\n","    \n","    params = {\"w\": w,\n","              \"b\": b}\n","    \n","    grads = {\"dw\": dw,\n","             \"db\": db}\n","    \n","    return params, grads, costs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJtDKl3jvqze","colab_type":"code","colab":{}},"source":["params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n","\n","print (\"w = \" + str(params[\"w\"]))\n","print (\"b = \" + str(params[\"b\"]))\n","print (\"dw = \" + str(grads[\"dw\"]))\n","print (\"db = \" + str(grads[\"db\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GFAGoK_Svqzf","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**: \n","\n","<table style=\"width:40%\">\n","    <tr>\n","       <td> **w** </td>\n","       <td>[[ 0.19033591] \n","     [ 0.12259159]] </td>\n","    </tr>\n","    <tr>\n","       <td> **b** </td>\n","       <td> 1.92535983008 </td>\n","    </tr>\n","    <tr>\n","       <td> **dw** </td>\n","       <td> [[ 0.67752042]\n"," [ 1.41625495]] </td>\n","    </tr>\n","    <tr>\n","       <td> **db** </td>\n","       <td> 0.219194504541 </td>\n","    </tr>\n","\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"RY6T3rh3vqzg","colab_type":"text"},"source":["## <font color=\"blue\"> Question 7\n","\n","이전 `optimize()` 함수는 학습된 w와 b를 출력한다. 이제는 이 w와 b로 x(image)의 y(label)를 예측해야한다.    \n","    \n","**문제:** 아래 조건을 만족하는 `predict()`함수를 완성하시오. \n","\n","1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n","\n","2. A의 각 원소들을 0 (if activation <= 0.5) 또는 1 (if activation > 0.5) 변환하고, 이 값들을 `Y_prediction` vector에 할당하시오. \n","    \n","**hint:** If you wish, you can use an `if`/`else` statement in a `for` loop (though there is also a way to vectorize this). "]},{"cell_type":"code","metadata":{"id":"L8SaoSy0vqzg","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: predict\n","\n","def predict(w, b, X):\n","    '''\n","    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n","    \n","    Arguments:\n","    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n","    b -- bias, a scalar\n","    X -- data of size (num_px * num_px * 3, number of examples)\n","    \n","    Returns:\n","    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n","    '''\n","    \n","    m = X.shape[1]\n","    Y_prediction = np.zeros((1,m))\n","    w = w.reshape(X.shape[0], 1)\n","    \n","    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n","\n","    #sigmoid함수값\n","    ### START CODE HERE ### (≈ 1 line of code)\n","    A = \n","    ### END CODE HERE ###\n","    \n","    for i in range(A.shape[1]):\n","        \n","        # Convert probabilities A[0,i] to actual predictions p[0,i]\n","        ### START CODE HERE ### (≈ 4 lines of code)\n","        \n","        \n","        \n","        \n","        ### END CODE HERE ###\n","    \n","    assert(Y_prediction.shape == (1, m))\n","    \n","    return Y_prediction"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUtG5lv7vqzi","colab_type":"code","colab":{}},"source":["w = np.array([[0.1124579],[0.23106775]])\n","b = -0.3\n","X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n","print (\"predictions = \" + str(predict(w, b, X)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HOuRODsqvqzk","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**: \n","\n","<table style=\"width:30%\">\n","    <tr>\n","         <td>\n","             **predictions**\n","         </td>\n","          <td>\n","            [[ 1.  1.  0.]]\n","         </td>  \n","   </tr>\n","\n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"FnyV1d36vqzk","colab_type":"text"},"source":["<font color='blue'>\n","**What to remember:**\n","You've implemented several functions that:\n","- Initialize (w,b)\n","- Optimize the loss iteratively to learn parameters (w,b):\n","    - computing the cost and its gradient \n","    - updating the parameters using gradient descent\n","- Use the learned (w,b) to predict the labels for a given set of examples"]},{"cell_type":"markdown","metadata":{"id":"KFX65KVjvqzl","colab_type":"text"},"source":["---------"]},{"cell_type":"markdown","metadata":{"id":"TqdDn4-9vqzl","colab_type":"text"},"source":["## 5. Merge all functions into a model ##\n","\n","### 5-1) training & test model\n","\n","You will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.\n","\n","## <font color=\"blue\"> Question 8\n","\n","**문제:** 아래 조건을 만족하는 `model()`함수를 완성하시오.\n","- Y_prediction_test for your predictions on the test set\n","- Y_prediction_train for your predictions on the train set\n","- w, costs, grads for the outputs of optimize()\n","    \n","**hint:** 기존에 위에서 만든 함수들을 여기서 합쳐서 Neural Network(모델)를 만듭니다."]},{"cell_type":"code","metadata":{"id":"H2U11T-bvqzl","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: model\n","\n","def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n","    \"\"\"\n","    Builds the logistic regression model by calling the function you've implemented previously\n","    \n","    Arguments:\n","    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n","    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n","    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n","    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n","    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n","    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n","    print_cost -- Set to true to print the cost every 100 iterations\n","    \n","    Returns:\n","    d -- dictionary containing information about the model.\n","    \"\"\"\n","    \n","    ### START CODE HERE ###\n","    \n","    # initialize parameters with zeros (≈ 1 line of code)\n","    w, b = \n","\n","    # Gradient descent (≈ 1 line of code)\n","    parameters, grads, costs = \n","    \n","    # Retrieve parameters w and b from dictionary \"parameters\"\n","    w = parameters[\"w\"]\n","    b = parameters[\"b\"]\n","    \n","    # Predict test/train set examples (≈ 2 lines of code)\n","    Y_prediction_test = \n","    Y_prediction_train =\n","\n","    ### END CODE HERE ###\n","\n","    # Print train/test Errors\n","    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n","    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n","\n","    \n","    d = {\"costs\": costs,\n","         \"Y_prediction_test\": Y_prediction_test, \n","         \"Y_prediction_train\" : Y_prediction_train, \n","         \"w\" : w, \n","         \"b\" : b,\n","         \"learning_rate\" : learning_rate,\n","         \"num_iterations\": num_iterations}\n","    \n","    return d"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9suWXwhBvqzo","colab_type":"text"},"source":["Run the following cell to train your model."]},{"cell_type":"code","metadata":{"id":"qXkSN9I-vqzo","colab_type":"code","colab":{}},"source":["d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.0025, print_cost = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DxIWCW1hvqzq","colab_type":"text"},"source":["**값이 오른쪽 table과 같다면 정답입니다**: \n","\n","<table style=\"width:40%\"> \n","    <tr>\n","        <td> **Cost after iteration 0**  </td> \n","        <td> 0.693147 </td>\n","    </tr>\n","      <tr>\n","        <td> <center> $\\vdots$ </center> </td> \n","        <td> <center> $\\vdots$ </center> </td> \n","    </tr>  \n","    <tr>\n","        <td> **Train Accuracy**  </td> \n","        <td> 99.0 % </td>\n","    </tr>\n","    <tr>\n","        <td>**Test Accuracy** </td> \n","        <td> 82.0 % </td>\n","    </tr>\n","</table> \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iiez8BG3vqzq","colab_type":"text"},"source":["Let's also plot the cost function and the gradients."]},{"cell_type":"code","metadata":{"id":"qQUm5Zpovqzq","colab_type":"code","colab":{}},"source":["# Plot learning curve (with costs)\n","costs = np.squeeze(d['costs'])\n","plt.plot(costs)\n","plt.ylabel('cost')\n","plt.xlabel('iterations (per hundreds)')\n","plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZE8hcefPvqzs","colab_type":"text"},"source":["**생각해보기:**\n","- training accuracy는 100%에 가깝습니다.\n","- test accuracy는 82%입니다.\n","- 이 모델은 좋은 모델일까요? \n","- 지금 현상을 뭐라고 할까요? 궁금하신 분은 'overfitting'을 검색해보셔도 좋습니다. 이는 5주차에 배웁니다.\n","\n","매주마다 점차 더 깊은 모델에 도전해봅니다."]},{"cell_type":"markdown","metadata":{"id":"j_dwWUIUvqzs","colab_type":"text"},"source":["**Interpretation**:\n","You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations(3000으로) in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called **overfitting.** "]},{"cell_type":"markdown","metadata":{"id":"UaXxXzQrvqzs","colab_type":"text"},"source":["### 5-2) test set 하나씩 test"]},{"cell_type":"code","metadata":{"id":"k8gZXgFovqzt","colab_type":"code","colab":{}},"source":["# Example of a picture that was wrongly classified.\n","index = 2\n","plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n","print (\"y = \" + str(test_set_y[:,index]) + \", you predicted that it is a \\\"\" + classes[int(d[\"Y_prediction_test\"][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5LwoD5Hvqzv","colab_type":"text"},"source":["-------"]},{"cell_type":"markdown","metadata":{"id":"6DvLVE9Lvqzv","colab_type":"text"},"source":["## (Bonus) 6. Test with your own image (optional/ungraded exercise) ##\n","\n","Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:\n","   1. 여러분의 이미지를 \"images\" 폴더 안에 넣습니다.\n","   2. 그 이미지의 이름을 \"my_image.jpg\"로 설정합니다. (확장자가 png 등이면 실행 불가 / 반드시 jpg여야 합니다.)\n","   3. 코드를 실행하면 여러분의 이미지가 고양이인지 판별합니다.(1 = cat, 0 = non-cat)!"]},{"cell_type":"code","metadata":{"id":"9NKIJKZDvqzv","colab_type":"code","colab":{}},"source":["## START CODE HERE ## (PUT YOUR IMAGE NAME) \n","my_image = \"my_image.jpg\"   # change this to the name of your image file \n","## END CODE HERE ##\n","\n","# We preprocess the image to fit your algorithm.\n","fname = \"images/\" + my_image\n","image = pilimg.open(fname)\n","image = np.array(image)\n","image = image/255.\n","my_image = cv2.resize(image, dsize=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n","my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n","\n","plt.imshow(image)\n","print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZOtgoAkFvqzx","colab_type":"text"},"source":["<font color='blue'>\n","**What to remember from this assignment:**\n","1. Preprocessing the dataset is important.\n","2. You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model().\n","3. Tuning the learning rate (which is an example of a \"hyperparameter\") can make a big difference to the algorithm. You will see more examples of this later in this course!"]},{"cell_type":"markdown","metadata":{"id":"dCa_2SY3vqzy","colab_type":"text"},"source":["Finally, if you'd like, we invite you to try different things on this Notebook. Make sure you submit before trying anything. Once you submit, things you can play with include:\n","    - Play with the learning rate and the number of iterations\n","    - Try different initialization methods and compare the results\n","    - Test other preprocessings (center the data, or divide each row by its standard deviation)"]},{"cell_type":"markdown","metadata":{"id":"bURXUZYQvqzy","colab_type":"text"},"source":["Bibliography:\n","- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n","- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"]}]}